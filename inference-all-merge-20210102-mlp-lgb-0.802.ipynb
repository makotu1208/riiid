{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026499,
     "end_time": "2021-01-06T06:51:28.822908",
     "exception": false,
     "start_time": "2021-01-06T06:51:28.796409",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- 75% data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026011,
     "end_time": "2021-01-06T06:51:28.873482",
     "exception": false,
     "start_time": "2021-01-06T06:51:28.847471",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Reading Data and Importing Libraries ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T06:51:28.928098Z",
     "iopub.status.busy": "2021-01-06T06:51:28.927374Z",
     "iopub.status.idle": "2021-01-06T06:51:28.929801Z",
     "shell.execute_reply": "2021-01-06T06:51:28.930339Z"
    },
    "papermill": {
     "duration": 0.031965,
     "end_time": "2021-01-06T06:51:28.930464",
     "exception": false,
     "start_time": "2021-01-06T06:51:28.898499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setting debug or not\n",
    "check_test = False # check_testの場合、推論結果を最後にall_testオブジェクトで出力。（sub時はFalse）\n",
    "use_train = False # Trueの場合trainの最初の1000行を使って推論 (sub時はFalse)\n",
    "del_test_dict = False # Trueの場合、trainを使うとき、指定列（下で指定）の辞書を初期化した結果を出力する（学習用DMとの比較を可能にする）（sub時はFalse）\n",
    "\n",
    "if del_test_dict:\n",
    "    # にのぴーfeatureの辞書を初期化して、trainと同等の結果が出てくるようにする\n",
    "    fill_nan_cols = []\n",
    "        \n",
    "    #fill_0_cols = ['un_acs_u_p_wt_same_que', 'un_acs_u_p_per_same_que']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T06:51:28.986052Z",
     "iopub.status.busy": "2021-01-06T06:51:28.985537Z",
     "iopub.status.idle": "2021-01-06T06:51:29.729031Z",
     "shell.execute_reply": "2021-01-06T06:51:29.728559Z"
    },
    "papermill": {
     "duration": 0.773848,
     "end_time": "2021-01-06T06:51:29.729141",
     "exception": false,
     "start_time": "2021-01-06T06:51:28.955293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import ast\n",
    "import time\n",
    "import gc\n",
    "import scipy as sp\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore') \n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T06:51:29.785194Z",
     "iopub.status.busy": "2021-01-06T06:51:29.784653Z",
     "iopub.status.idle": "2021-01-06T06:51:35.470466Z",
     "shell.execute_reply": "2021-01-06T06:51:35.469482Z"
    },
    "papermill": {
     "duration": 5.716039,
     "end_time": "2021-01-06T06:51:35.470585",
     "exception": false,
     "start_time": "2021-01-06T06:51:29.754546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/kaggle/input/riiid-idem-part\")\n",
    "\n",
    "from ide_nn.src.share import (\n",
    "    load_params_MLP,\n",
    "#     load_params_TabNet,\n",
    "    load_params_Linear,\n",
    "    load_FeatureTransformer,\n",
    "    load_MLP,\n",
    "#     load_TabNet,\n",
    "    load_Linear,\n",
    "    predict_MLP,\n",
    "#     predict_TabNet,\n",
    "    predict_Linear,\n",
    ")\n",
    "\n",
    "\n",
    "mlp_params = load_params_MLP(src_dir=\"/kaggle/input/riiid-idem-part\")\n",
    "mlp_ft = load_FeatureTransformer(mlp_params)\n",
    "mlp_model = load_MLP(mlp_params, mlp_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024757,
     "end_time": "2021-01-06T06:51:35.520875",
     "exception": false,
     "start_time": "2021-01-06T06:51:35.496118",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## read data/model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024704,
     "end_time": "2021-01-06T06:51:35.570412",
     "exception": false,
     "start_time": "2021-01-06T06:51:35.545708",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## make content master\n",
    "- content_idとlecture_idをまとめた形に加工\n",
    "- lectureとcontent_idが被っている場合、partはcontentの方を採用する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T06:51:35.629669Z",
     "iopub.status.busy": "2021-01-06T06:51:35.629126Z",
     "iopub.status.idle": "2021-01-06T06:51:36.124367Z",
     "shell.execute_reply": "2021-01-06T06:51:36.123292Z"
    },
    "papermill": {
     "duration": 0.529097,
     "end_time": "2021-01-06T06:51:36.124487",
     "exception": false,
     "start_time": "2021-01-06T06:51:35.595390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#read base dataset\n",
    "questions = pd.read_csv('../input/riiid-test-answer-prediction/questions.csv')\n",
    "questions['L_R'] = np.where(questions['part'] < 5, 1, 0)\n",
    "lectures = pd.read_csv('../input/riiid-test-answer-prediction/lectures.csv')\n",
    "\n",
    "#read tag master\n",
    "tag_master = pd.read_pickle('../input/riiid-feature/tag_master.pickle')\n",
    "content_diff_master = pd.read_pickle('../input/riiid-feature/content_diff_master.pickle')\n",
    "\n",
    "# read content features\n",
    "content_elp_accuracy = pd.read_pickle('../input/riiid-feature/content_elp_accuracy.pickle')\n",
    "content_elp_count_ratio = pd.read_pickle('../input/riiid-feature/content_elp_count_ratio.pickle')\n",
    "content_lag_accuracy = pd.read_pickle('../input/riiid-feature/content_lag_accuracy.pickle')\n",
    "content_lag_count_ratio = pd.read_pickle('../input/riiid-feature/content_lag_count_ratio.pickle')\n",
    "content_count_ratio = pd.read_pickle('../input/riiid-feature/content_count_ratio_df.pickle')\n",
    "content_accuracy = pd.read_pickle('../input/riiid-feature/content_accuracy_df.pickle')\n",
    "content_pivot = pd.read_pickle('../input/riiid-feature/bin_pivot_df.pickle')\n",
    "content_dup_ratio = pd.read_pickle('../input/riiid-feature/content_dup_ratio_df.pickle')\n",
    "content_unacc_df = pd.read_csv('../input/riiid-feature/content_unacc_user_prior_user_answered_correctly.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T06:51:36.179468Z",
     "iopub.status.busy": "2021-01-06T06:51:36.178901Z",
     "iopub.status.idle": "2021-01-06T06:51:36.271386Z",
     "shell.execute_reply": "2021-01-06T06:51:36.270865Z"
    },
    "papermill": {
     "duration": 0.121477,
     "end_time": "2021-01-06T06:51:36.271510",
     "exception": false,
     "start_time": "2021-01-06T06:51:36.150033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# content * lagtime_bin\n",
    "content_same_lag_accuracy = pd.read_pickle('../input/riiid-feature/content_accu_lag.pickle')\n",
    "\n",
    "# content * accu_bin\n",
    "content_same_prioraccu_accuracy = pd.read_pickle('../input/riiid-feature/content_same_user_accu.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T06:51:36.339393Z",
     "iopub.status.busy": "2021-01-06T06:51:36.334904Z",
     "iopub.status.idle": "2021-01-06T06:51:36.371117Z",
     "shell.execute_reply": "2021-01-06T06:51:36.370663Z"
    },
    "papermill": {
     "duration": 0.074004,
     "end_time": "2021-01-06T06:51:36.371246",
     "exception": false,
     "start_time": "2021-01-06T06:51:36.297242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add L/R tag difficult features\n",
    "questions.rename(columns = {'question_id':'content_id'}, inplace = True)\n",
    "questions['L_R'] = np.where(questions['part'] < 5, 1, 0)\n",
    "questions = questions.merge(tag_master[['content_id', 'tag']], on = 'content_id', how = 'left')\n",
    "questions = questions.merge(content_diff_master, on = 'content_id', how = 'left')\n",
    "\n",
    "# contentとlectureを縦に結合し、欠損埋め\n",
    "lectures.rename(columns = {'lecture_id':'content_id'}, inplace = True)\n",
    "questions_all = pd.concat([questions[['content_id']], lectures[['content_id']]],axis=0).drop_duplicates().reset_index(drop=True)\n",
    "questions_all = questions_all.merge(questions[['content_id', 'bundle_id', 'part', 'L_R', 'tag', 'prob_difficuly']], on = 'content_id', how = 'left')\n",
    "questions_all['part'].fillna(99, inplace = True)\n",
    "questions_all['L_R'].fillna(99, inplace = True)\n",
    "questions_all['bundle_id'].fillna(99999, inplace = True)\n",
    "questions_all['tag'].fillna(999, inplace = True)\n",
    "questions = questions_all.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T06:51:36.427352Z",
     "iopub.status.busy": "2021-01-06T06:51:36.425640Z",
     "iopub.status.idle": "2021-01-06T06:51:36.427948Z",
     "shell.execute_reply": "2021-01-06T06:51:36.428391Z"
    },
    "papermill": {
     "duration": 0.031678,
     "end_time": "2021-01-06T06:51:36.428496",
     "exception": false,
     "start_time": "2021-01-06T06:51:36.396818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del questions_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025865,
     "end_time": "2021-01-06T06:51:36.479841",
     "exception": false,
     "start_time": "2021-01-06T06:51:36.453976",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## モデルと特徴量を読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T06:51:36.533765Z",
     "iopub.status.busy": "2021-01-06T06:51:36.533266Z",
     "iopub.status.idle": "2021-01-06T06:51:42.844529Z",
     "shell.execute_reply": "2021-01-06T06:51:42.843485Z"
    },
    "papermill": {
     "duration": 6.339359,
     "end_time": "2021-01-06T06:51:42.844657",
     "exception": false,
     "start_time": "2021-01-06T06:51:36.505298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#read model/make dataset\n",
    "model = pd.read_pickle('../input/riiid-model/full_model_2.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T06:51:42.916769Z",
     "iopub.status.busy": "2021-01-06T06:51:42.916238Z",
     "iopub.status.idle": "2021-01-06T06:51:46.628010Z",
     "shell.execute_reply": "2021-01-06T06:51:46.626463Z"
    },
    "papermill": {
     "duration": 3.755781,
     "end_time": "2021-01-06T06:51:46.628127",
     "exception": false,
     "start_time": "2021-01-06T06:51:42.872346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## read feature\n",
    "# content\n",
    "content_base= pd.read_pickle('/kaggle/input/riiid-feature/content_df_base.pickle')\n",
    "content_df = pd.read_pickle('/kaggle/input/riiid-feature/content_df.pickle')\n",
    "content_difficult_df = pd.read_pickle('../input/riiid-feature/content_difficult_pred.pickle')\n",
    "answer_score_df = pd.read_pickle('../input/riiid-feature/answer_score_df.pickle')\n",
    "w2v_10 = pd.read_pickle('../input/riiid-feature/df_accu_cont_10_w2v.pickle')\n",
    "content_series = pd.read_pickle('../input/riiid-feature/content_series.pickle')\n",
    "lag_content = pd.read_pickle('../input/riiid-feature/lag_content_df.pickle')\n",
    "content_acc = pd.read_pickle('../input/riiid-feature/content_acc_considered_part.pickle')\n",
    "\n",
    "#user\n",
    "user_base = pd.read_pickle('../input/riiid-feature/user_answered_correctly_df.pickle')\n",
    "user_base_part = pd.read_pickle('../input/riiid-feature/user_answered_correctly_df_part.pickle')\n",
    "user_score = pd.read_pickle('../input/riiid-feature/user_score_df.pickle')\n",
    "del user_score['count']\n",
    "accu_df = pd.read_pickle('../input/riiid-feature/LR_df.pickle')\n",
    "last_accu_df = pd.read_pickle('../input/riiid-feature/last_accu_cont.pickle')\n",
    "last_content_lag_df = pd.read_pickle('../input/riiid-feature/last_content_lag_df.pickle')\n",
    "before_lecture_df = pd.read_pickle('../input/riiid-feature/before_lecture_df.pickle')\n",
    "before_lecture_df.fillna(0, inplace = True)\n",
    "diff_task_df = pd.read_pickle('../input/riiid-feature/diff_task_pred_features.pickle')\n",
    "dup_ratio_df = pd.read_pickle('../input/riiid-feature/dup_ratio_df.pickle')\n",
    "dup_row_num_df = pd.read_pickle('../input/riiid-feature/pred_dup_row_num.pickle')\n",
    "cont_difficulty_df = pd.read_pickle('../input/riiid-feature/pred_cont_difficulty.pickle')\n",
    "user_score_LR = pd.read_pickle('../input/riiid-feature/pred_user_score_LR.pickle')\n",
    "del user_score_LR['L_count'], user_score_LR['R_count']\n",
    "\n",
    "last_lag_bin_df = pd.read_pickle('../input/riiid-feature/last_lag_bin_df.pickle')\n",
    "last_elp_bin_df = pd.read_pickle('../input/riiid-feature/last_elp_bin_df.pickle')\n",
    "\n",
    "# user&part\n",
    "#user_unacc_df = pd.read_pickle('../input/riiid-feature/pred_cumsum_unaccu_df.pickle')\n",
    "#user_unacc_df.fillna(0, inplace = True)\n",
    "\n",
    "# time\n",
    "first_user_df = pd.read_pickle('../input/riiid-feature/first_user_df.pickle')\n",
    "lag_time_df = pd.read_pickle('../input/riiid-feature/last_time_stamp_w_start.pickle')\n",
    "prior_time_df = pd.read_pickle('../input/riiid-feature/prior_time_df.pickle')\n",
    "end_to_start_df = pd.read_pickle('../input/riiid-feature/last_end_to_start_df.pickle')\n",
    "session_time_df = pd.read_pickle('../input/riiid-feature/session_time.pickle')\n",
    "\n",
    "del session_time_df['session_last_accu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T06:51:46.686881Z",
     "iopub.status.busy": "2021-01-06T06:51:46.686328Z",
     "iopub.status.idle": "2021-01-06T06:52:16.785633Z",
     "shell.execute_reply": "2021-01-06T06:52:16.786813Z"
    },
    "papermill": {
     "duration": 30.132171,
     "end_time": "2021-01-06T06:52:16.786991",
     "exception": false,
     "start_time": "2021-01-06T06:51:46.654820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# matrix\n",
    "\n",
    "def pickle_load(path):\n",
    "    with open(path, mode='rb') as f:\n",
    "        data = pkl.load(f)\n",
    "        return data\n",
    "\n",
    "# user * content毎に前回のtimestampを入れたmatrix\n",
    "dup_time_matrix = sp.sparse.load_npz('../input/add-matrix-data/dup_time_matrix.npz')\n",
    "dup_time_matrix = dup_time_matrix.tolil()\n",
    "\n",
    "# user * tag毎に今までの回答回数を入れたmatrix\n",
    "tag_matrix = sp.sparse.load_npz('../input/add-matrix-data/tag_matrix.npz')\n",
    "tag_matrix = tag_matrix.tolil()\n",
    "\n",
    "# 各種master（idをmatrixの列番号に変換するマスタ）\n",
    "user_master = pickle_load( '../input/add-matrix-data/user_master.pickle')\n",
    "content_master = pickle_load( '../input/add-matrix-data/content_master.pickle')\n",
    "tag_mat_master = pickle_load( '../input/add-matrix-data/tag_mat_master.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T06:52:17.007926Z",
     "iopub.status.busy": "2021-01-06T06:52:17.007097Z",
     "iopub.status.idle": "2021-01-06T06:52:17.014539Z",
     "shell.execute_reply": "2021-01-06T06:52:17.015545Z"
    },
    "papermill": {
     "duration": 0.142257,
     "end_time": "2021-01-06T06:52:17.015707",
     "exception": false,
     "start_time": "2021-01-06T06:52:16.873450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rename\n",
    "first_user_df.rename(columns = {'content_user_cover_ratio':'first_user_ratio'}, inplace = True)\n",
    "lag_time_df.rename(columns = {'timestamp':'last_timestamp'}, inplace = True)\n",
    "session_time_df.rename(columns = {'session_prob':'prior_session_prob'}, inplace = True)\n",
    "lag_content.rename(columns = {'lag_time':'mean_lag_time'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.043578,
     "end_time": "2021-01-06T06:52:17.104040",
     "exception": false,
     "start_time": "2021-01-06T06:52:17.060462",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## merge(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T06:52:19.172037Z",
     "iopub.status.busy": "2021-01-06T06:52:19.170867Z",
     "iopub.status.idle": "2021-01-06T06:52:21.357333Z",
     "shell.execute_reply": "2021-01-06T06:52:21.356842Z"
    },
    "papermill": {
     "duration": 4.207569,
     "end_time": "2021-01-06T06:52:21.357439",
     "exception": false,
     "start_time": "2021-01-06T06:52:17.149870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.02 s, sys: 109 ms, total: 2.13 s\n",
      "Wall time: 2.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "user_base = user_base.merge(user_base_part, on = 'user_id', how = 'left')\n",
    "user_base = user_base.merge(accu_df, on = 'user_id', how = 'left')\n",
    "user_base = user_base.merge(user_score, on = 'user_id', how = 'left')\n",
    "user_base = user_base.merge(first_user_df, on = 'user_id', how = 'left') # 0.442076\n",
    "user_base = user_base.merge(lag_time_df, on = 'user_id', how = 'left')\n",
    "user_base = user_base.merge(content_difficult_df, on = 'user_id', how = 'left')\n",
    "user_base = user_base.merge(before_lecture_df, on = 'user_id', how = 'left')\n",
    "user_base = user_base.merge(last_accu_df, on = 'user_id', how = 'left')\n",
    "user_base = user_base.merge(end_to_start_df, on = 'user_id', how = 'left')\n",
    "user_base = user_base.merge(session_time_df, on = 'user_id', how = 'left')\n",
    "user_base = user_base.merge(last_content_lag_df, on = 'user_id', how = 'left')\n",
    "user_base = user_base.merge(diff_task_df, on = 'user_id', how = 'left')\n",
    "user_base = user_base.merge(dup_ratio_df, on = 'user_id', how = 'left')\n",
    "user_base = user_base.merge(dup_row_num_df, on = 'user_id', how = 'left')\n",
    "user_base = user_base.merge(cont_difficulty_df, on = 'user_id', how = 'left')\n",
    "user_base = user_base.merge(user_score_LR, on = 'user_id', how = 'left')\n",
    "user_base = user_base.merge(last_lag_bin_df, on = 'user_id', how = 'left')\n",
    "user_base = user_base.merge(last_elp_bin_df, on = 'user_id', how = 'left')\n",
    "user_base['lag_time_bin'] = np.nan\n",
    "user_base['elp_time_bin'] = np.nan\n",
    "user_base['prior_user_answered_correctly_bin'] = np.nan\n",
    "user_base['prior_answer'] = np.nan # elp_time系の変数\n",
    "\n",
    "content_base = content_base.merge(content_df, on = 'content_id', how = 'left')\n",
    "content_base = content_base.merge(w2v_10, on = 'content_id', how = 'left')\n",
    "content_base = content_base.merge(content_series, on = 'content_id', how = 'left')\n",
    "content_base = content_base.merge(lag_content, on = 'content_id', how = 'left')\n",
    "content_base = content_base.merge(questions[['part', 'bundle_id']], left_on = 'content_id', right_index = True, how = 'left')\n",
    "content_base = content_base.merge(prior_time_df, on = 'bundle_id', how = 'left')\n",
    "\n",
    "content_base = content_base.merge(content_elp_accuracy, on = 'content_id', how = 'left')\n",
    "content_base = content_base.merge(content_elp_count_ratio, on = 'content_id', how = 'left')\n",
    "content_base = content_base.merge(content_lag_accuracy, on = 'content_id', how = 'left')\n",
    "content_base = content_base.merge(content_lag_count_ratio, on = 'content_id', how = 'left')\n",
    "content_base = content_base.merge(content_count_ratio, on = 'content_id', how = 'left')\n",
    "content_base = content_base.merge(content_accuracy, on = 'content_id', how = 'left')\n",
    "content_base = content_base.merge(content_pivot, on = 'content_id', how = 'left')\n",
    "content_base = content_base.merge(content_dup_ratio, on = 'content_id', how = 'left')\n",
    "\n",
    "\n",
    "# ninopy features\n",
    "content_base = content_base.merge(content_acc, on = 'content_id', how = 'left')\n",
    "content_base = content_base.merge(content_unacc_df, on = 'content_id', how = 'left')\n",
    "\n",
    "content_base.loc[content_base['answered_correctly_content'] == 0, 'answered_correctly_content'] = content_base['answered_correctly_content'].mean()\n",
    "\n",
    "for col in ['answered_correctly_content_first_look','fix_answered_correctly_content_first_look']:\n",
    "    content_base[col].fillna(content_base[col].mean(), inplace = True)\n",
    "\n",
    "del accu_df, content_difficult_df, before_lecture_df, prior_time_df, first_user_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T06:52:21.421946Z",
     "iopub.status.busy": "2021-01-06T06:52:21.421120Z",
     "iopub.status.idle": "2021-01-06T06:52:21.444571Z",
     "shell.execute_reply": "2021-01-06T06:52:21.443687Z"
    },
    "papermill": {
     "duration": 0.060131,
     "end_time": "2021-01-06T06:52:21.444674",
     "exception": false,
     "start_time": "2021-01-06T06:52:21.384543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 確率系のfeature作成\n",
    "user_base['prior_user_answered_correctly'] = user_base['answered_correctly_cumsum'] / user_base['count']\n",
    "user_base['prior_L_accu'] = user_base['L_accu_sum'] / user_base['L_count']\n",
    "user_base['prior_R_accu'] = user_base['R_accu_sum'] / user_base['R_count']\n",
    "user_base['prior_user_score'] = user_base['user_score_cumsum'] / user_base['count']\n",
    "user_base['prior_session_prob'] = user_base['prior_session_prob']\n",
    "user_base['prior_L_user_score'] = user_base['L_score'] / user_base['L_count']\n",
    "user_base['prior_R_user_score'] = user_base['R_score'] / user_base['R_count']\n",
    "user_base['difficulty_50_ratio'] = user_base['difficulty_50'] / user_base['count_dif_50']\n",
    "user_base['difficulty_75_ratio'] = user_base['difficulty_75'] / user_base['count_dif_75']\n",
    "user_base['difficulty_1_ratio'] = user_base['difficulty_1'] / user_base['count_dif_1']\n",
    "user_base['prior_p2_accu'] = user_base['p2_accu_sum'] / user_base['p2_count']\n",
    "user_base['prior_p5_accu'] = user_base['p5_accu_sum'] / user_base['p5_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T06:52:21.504391Z",
     "iopub.status.busy": "2021-01-06T06:52:21.502608Z",
     "iopub.status.idle": "2021-01-06T06:52:21.504997Z",
     "shell.execute_reply": "2021-01-06T06:52:21.505478Z"
    },
    "papermill": {
     "duration": 0.033549,
     "end_time": "2021-01-06T06:52:21.505590",
     "exception": false,
     "start_time": "2021-01-06T06:52:21.472041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#user_unacc_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T06:52:21.565464Z",
     "iopub.status.busy": "2021-01-06T06:52:21.564862Z",
     "iopub.status.idle": "2021-01-06T06:52:21.567814Z",
     "shell.execute_reply": "2021-01-06T06:52:21.568210Z"
    },
    "papermill": {
     "duration": 0.035874,
     "end_time": "2021-01-06T06:52:21.568309",
     "exception": false,
     "start_time": "2021-01-06T06:52:21.532435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# debug用\n",
    "if use_train:\n",
    "    print('use_train')\n",
    "    if del_test_dict:\n",
    "        print('del_test_dict')\n",
    "        for col in list(user_base.columns[1:]):\n",
    "            user_base[col] = 0\n",
    "            # 辞書のデフォにnanを入れる変数たち\n",
    "            for col in ['un_acs_u_p_wt_same_que_avg', 'un_acs_u_p_per_same_que_avg',\n",
    "                    'diff_un_acs_u_p_per_same_que_avg', 'diff_un_acs_u_p_wt_same_que_avg', \n",
    "                    'ratio_un_acs_u_p_per_same_que_avg','ratio_un_acs_u_p_wt_same_que_avg']:\n",
    "                user_unacc_df[col] = np.nan\n",
    "                \n",
    "        for col in ['un_acs_u_p_wt_same_que', 'un_acs_u_p_per_same_que']:\n",
    "            \n",
    "            user_unacc_df[col] = 0\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026663,
     "end_time": "2021-01-06T06:52:21.621670",
     "exception": false,
     "start_time": "2021-01-06T06:52:21.595007",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## make dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T06:52:21.679629Z",
     "iopub.status.busy": "2021-01-06T06:52:21.678877Z",
     "iopub.status.idle": "2021-01-06T06:52:21.681115Z",
     "shell.execute_reply": "2021-01-06T06:52:21.681551Z"
    },
    "papermill": {
     "duration": 0.032874,
     "end_time": "2021-01-06T06:52:21.681654",
     "exception": false,
     "start_time": "2021-01-06T06:52:21.648780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#user_unacc_dict = user_unacc_df.set_index(['user_id', 'part']).to_dict(orient='dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T06:52:21.742707Z",
     "iopub.status.busy": "2021-01-06T06:52:21.741819Z",
     "iopub.status.idle": "2021-01-06T06:52:37.887133Z",
     "shell.execute_reply": "2021-01-06T06:52:37.889048Z"
    },
    "papermill": {
     "duration": 16.180012,
     "end_time": "2021-01-06T06:52:37.889291",
     "exception": false,
     "start_time": "2021-01-06T06:52:21.709279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_dict\n",
      "content_dict\n",
      "user_content_dict\n",
      "same_lag_dict\n",
      "CPU times: user 14.5 s, sys: 1.62 s, total: 16.1 s\n",
      "Wall time: 16.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# make dict\n",
    "print('user_dict')\n",
    "user_accu_dict = user_base.set_index(['user_id']).to_dict(orient='dict')\n",
    "print('content_dict')\n",
    "content_dict = content_df[['content_id', 'answered_correctly_content_first_look', 'content_user_cover_ratio']\n",
    "                         ].set_index(['content_id']).to_dict(orient='dict')\n",
    "print('user_content_dict')\n",
    "answer_score_dict = answer_score_df.set_index(['content_id', 'user_answer']).to_dict(orient='dict')\n",
    "\n",
    "print('same_lag_dict')\n",
    "content_same_lag_accuracy_dict = content_same_lag_accuracy.set_index(['content_id', 'lag_time_bin']).to_dict(orient='dict')\n",
    "content_same_prioraccu_accuracy_dict = content_same_prioraccu_accuracy.set_index(['content_id', 'prior_user_answered_correctly_bin']).to_dict(orient='dict')\n",
    "\n",
    "\n",
    "del user_base, content_df, answer_score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027978,
     "end_time": "2021-01-06T06:52:37.953207",
     "exception": false,
     "start_time": "2021-01-06T06:52:37.925229",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## set index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T06:52:38.016506Z",
     "iopub.status.busy": "2021-01-06T06:52:38.014756Z",
     "iopub.status.idle": "2021-01-06T06:52:38.020857Z",
     "shell.execute_reply": "2021-01-06T06:52:38.020388Z"
    },
    "papermill": {
     "duration": 0.039142,
     "end_time": "2021-01-06T06:52:38.020944",
     "exception": false,
     "start_time": "2021-01-06T06:52:37.981802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dictとは別に紐づける特徴量（content系）にはindexを振る\n",
    "questions = questions.set_index('content_id')\n",
    "content_base = content_base.set_index('content_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027542,
     "end_time": "2021-01-06T06:52:38.076917",
     "exception": false,
     "start_time": "2021-01-06T06:52:38.049375",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 推論メインパート"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02828,
     "end_time": "2021-01-06T06:52:38.133475",
     "exception": false,
     "start_time": "2021-01-06T06:52:38.105195",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## デバック用のループ関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T06:52:38.213326Z",
     "iopub.status.busy": "2021-01-06T06:52:38.211569Z",
     "iopub.status.idle": "2021-01-06T06:52:38.213948Z",
     "shell.execute_reply": "2021-01-06T06:52:38.214370Z"
    },
    "papermill": {
     "duration": 0.053136,
     "end_time": "2021-01-06T06:52:38.214476",
     "exception": false,
     "start_time": "2021-01-06T06:52:38.161340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Iter_Valid(object):\n",
    "    def __init__(self, df, max_user=1000):\n",
    "        df = df.reset_index(drop=True)\n",
    "        self.df = df\n",
    "        self.user_answer = df['user_answer'].astype(str).values\n",
    "        self.answered_correctly = df['answered_correctly'].astype(str).values\n",
    "        df['prior_group_responses'] = \"[]\"\n",
    "        df['prior_group_answers_correct'] = \"[]\"\n",
    "        self.sample_df = df[df['content_type_id'] == 0][['row_id']]\n",
    "        self.sample_df['answered_correctly'] = 0\n",
    "        self.len = len(df)\n",
    "        self.user_id = df.user_id.values\n",
    "        self.task_container_id = df.task_container_id.values\n",
    "        self.content_type_id = df.content_type_id.values\n",
    "        self.max_user = max_user\n",
    "        self.current = 0\n",
    "        self.pre_user_answer_list = []\n",
    "        self.pre_answered_correctly_list = []\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def fix_df(self, user_answer_list, answered_correctly_list, pre_start):\n",
    "        df= self.df[pre_start:self.current].copy()\n",
    "        sample_df = self.sample_df[pre_start:self.current].copy()\n",
    "        df.loc[pre_start,'prior_group_responses'] = '[' + \",\".join(self.pre_user_answer_list) + ']'\n",
    "        df.loc[pre_start,'prior_group_answers_correct'] = '[' + \",\".join(self.pre_answered_correctly_list) + ']'\n",
    "        self.pre_user_answer_list = user_answer_list\n",
    "        self.pre_answered_correctly_list = answered_correctly_list\n",
    "        return df, sample_df\n",
    "\n",
    "    def __next__(self):\n",
    "        added_user = set()\n",
    "        pre_start = self.current\n",
    "        pre_added_user = -1\n",
    "        pre_task_container_id = -1\n",
    "        pre_content_type_id = -1\n",
    "        user_answer_list = []\n",
    "        answered_correctly_list = []\n",
    "        while self.current < self.len:\n",
    "            crr_user_id = self.user_id[self.current]\n",
    "            crr_task_container_id = self.task_container_id[self.current]\n",
    "            crr_content_type_id = self.content_type_id[self.current]\n",
    "            if crr_user_id in added_user and (crr_user_id != pre_added_user or (crr_task_container_id != pre_task_container_id and crr_content_type_id == 0 and pre_content_type_id == 0)):\n",
    "                \n",
    "                # known user(not prev user or (differnt task container and both question))\n",
    "                return self.fix_df(user_answer_list, answered_correctly_list, pre_start)\n",
    "            if len(added_user) == self.max_user:\n",
    "                if  crr_user_id == pre_added_user and (crr_task_container_id == pre_task_container_id or crr_content_type_id == 1):\n",
    "                    user_answer_list.append(self.user_answer[self.current])\n",
    "                    answered_correctly_list.append(self.answered_correctly[self.current])\n",
    "                    self.current += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    return self.fix_df(user_answer_list, answered_correctly_list, pre_start)\n",
    "            added_user.add(crr_user_id)\n",
    "            pre_added_user = crr_user_id\n",
    "            pre_task_container_id = crr_task_container_id\n",
    "            pre_content_type_id = crr_content_type_id\n",
    "            user_answer_list.append(self.user_answer[self.current])\n",
    "            answered_correctly_list.append(self.answered_correctly[self.current])\n",
    "            self.current += 1\n",
    "        if pre_start < self.current:\n",
    "            return self.fix_df(user_answer_list, answered_correctly_list, pre_start)\n",
    "        else:\n",
    "            raise StopIteration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.028046,
     "end_time": "2021-01-06T06:52:38.270379",
     "exception": false,
     "start_time": "2021-01-06T06:52:38.242333",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## bin系関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T06:52:38.334606Z",
     "iopub.status.busy": "2021-01-06T06:52:38.333903Z",
     "iopub.status.idle": "2021-01-06T06:52:38.336900Z",
     "shell.execute_reply": "2021-01-06T06:52:38.336483Z"
    },
    "papermill": {
     "duration": 0.038984,
     "end_time": "2021-01-06T06:52:38.336986",
     "exception": false,
     "start_time": "2021-01-06T06:52:38.298002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bin_lag_time(x):\n",
    "    if x <= 30000:\n",
    "        bin = 0\n",
    "    elif x < 65000:\n",
    "        bin = 1\n",
    "    elif x < 170000:\n",
    "        bin = 2\n",
    "    else:\n",
    "        bin = 3\n",
    "    return bin\n",
    "\n",
    "\n",
    "def bin_accuracy(x):\n",
    "    if x <= 0.55:\n",
    "        bin = 0\n",
    "    elif x < 0.65:\n",
    "        bin = 1\n",
    "    elif x < 0.75:\n",
    "        bin = 2\n",
    "    elif x <= 1:\n",
    "        bin = 3\n",
    "    else:\n",
    "        bin = 4 # np.nan\n",
    "    return bin\n",
    "\n",
    "\n",
    "def bin_elp_time(x):\n",
    "    if x <= 16000:\n",
    "        bin = 0\n",
    "    elif x < 21000:\n",
    "        bin = 1\n",
    "    elif x < 30000:\n",
    "        bin = 2\n",
    "    elif x < 300000:\n",
    "        bin = 3\n",
    "    else:\n",
    "        bin = 4 # np.nanと300000の枠\n",
    "    return bin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027889,
     "end_time": "2021-01-06T06:52:38.393125",
     "exception": false,
     "start_time": "2021-01-06T06:52:38.365236",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 使用変数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T06:52:38.462000Z",
     "iopub.status.busy": "2021-01-06T06:52:38.461215Z",
     "iopub.status.idle": "2021-01-06T06:52:38.463768Z",
     "shell.execute_reply": "2021-01-06T06:52:38.463362Z"
    },
    "papermill": {
     "duration": 0.04293,
     "end_time": "2021-01-06T06:52:38.463851",
     "exception": false,
     "start_time": "2021-01-06T06:52:38.420921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_col_lgb = [  \n",
    " 'prior_question_elapsed_time',\n",
    " 'lag_time',\n",
    " 'prior_user_answered_correctly',\n",
    " 'prior_user_score',\n",
    " 'count',\n",
    " 'count_part',\n",
    " 'content_user_cover_ratio',\n",
    " 'first_user_ratio',\n",
    " 'answered_correctly_content',\n",
    " 'answered_correctly_content_first_look',\n",
    " 'fix_answered_correctly_content_first_look',\n",
    " 'part',\n",
    " 'before_lecture',\n",
    " 'L_count', \n",
    " 'R_count', \n",
    " 'prior_L_accu', \n",
    " 'prior_R_accu',\n",
    " 'content_accu_mean',\n",
    " 'content_cumsum_ratio', \n",
    " 'ave_elapsed_time',\n",
    " 'prior_accu_continuous',\n",
    " 'prior_accu_no_continuous',\n",
    " 'dup_time',\n",
    " 'prior_end_to_start', \n",
    " 'content_series_mean',\n",
    " 'tag',\n",
    " 'prior_question_had_explanation',\n",
    " 'lec_num',\n",
    " 'session_time',\n",
    " 'session_count',\n",
    " 'prior_session_time',\n",
    " 'prior_session_prob',\n",
    " 'mean_lag_time',\n",
    " 'lag_user_ave',\n",
    " 'lag_user_p2_ave',\n",
    " 'lag_user_p5_ave',\n",
    " 'lag_c_p2',\n",
    " 'lag_c_p5',\n",
    " 'lag_task',\n",
    " 'dup_ratio',\n",
    " 'count_dif_50_ratio', \n",
    " 'count_dif_75_ratio', \n",
    " 'count_dif_1_ratio',\n",
    " 'difficulty_50_ratio',\n",
    " 'difficulty_75_ratio',\n",
    " 'difficulty_1_ratio',\n",
    " 'dup_row_num',\n",
    "\n",
    " 'prior_L_user_score',\n",
    " 'prior_R_user_score',\n",
    " 'user_score_ratio',\n",
    " 'prior_p2_accu',\n",
    " 'prior_p5_accu',\n",
    "    \n",
    " # lag_u_features\n",
    " 'lag_u_bin_0_accu_mean',\n",
    " 'lag_u_bin_1_accu_mean',\n",
    " 'lag_u_bin_2_accu_mean',\n",
    " 'lag_u_bin_3_accu_mean',\n",
    " 'lag_u_bin_0_count_ratio',\n",
    " 'lag_u_bin_1_count_ratio',\n",
    " 'lag_u_bin_2_count_ratio',\n",
    " 'lag_u_bin_3_count_ratio',\n",
    " 'elp_u_bin_0_accu_mean',\n",
    " 'elp_u_bin_1_accu_mean',\n",
    " 'elp_u_bin_2_accu_mean',\n",
    " 'elp_u_bin_3_accu_mean',\n",
    " 'elp_u_bin_0_count_ratio',\n",
    " 'elp_u_bin_1_count_ratio',\n",
    " 'elp_u_bin_2_count_ratio',\n",
    " 'elp_u_bin_3_count_ratio',\n",
    "    \n",
    " # content * prior_accu\n",
    " 'content_accuracy',\n",
    "    \n",
    " # content * lag\n",
    " 'same_lag_user_content_accuracy',\n",
    "    \n",
    " # lag\n",
    " 'content_lag_count_dist_0',\n",
    " 'content_lag_count_dist_1',\n",
    " 'content_lag_count_dist_2',\n",
    " 'content_lag_count_dist_3',\n",
    " 'same_lagbin_content_acc_mean_0',\n",
    " 'same_lagbin_content_acc_mean_1',\n",
    " 'same_lagbin_content_acc_mean_2',\n",
    " 'same_lagbin_content_acc_mean_3',\n",
    "    \n",
    " # elp\n",
    " 'content_elp_count_dist_0',\n",
    " 'content_elp_count_dist_1',\n",
    " 'content_elp_count_dist_2',\n",
    " 'content_elp_count_dist_3',\n",
    " 'same_elpbin_content_acc_mean_0',\n",
    " 'same_elpbin_content_acc_mean_1',\n",
    " 'same_elpbin_content_acc_mean_2',\n",
    " 'same_elpbin_content_acc_mean_3',\n",
    "    \n",
    " # acc\n",
    " 'content_bin_count_ratio_0',\n",
    " 'content_bin_count_ratio_1',\n",
    " 'content_bin_count_ratio_2',\n",
    " 'content_bin_count_ratio_3',\n",
    " 'same_prioracbin_content_acc_mean_0',\n",
    " 'same_prioracbin_content_acc_mean_1',\n",
    " 'same_prioracbin_content_acc_mean_2',\n",
    " 'same_prioracbin_content_acc_mean_3',\n",
    "    \n",
    " # ninopy\n",
    " 'content_unacc_user_prior_user_answered_correctly_mean',\n",
    " 'content_unacc_user_prior_user_answered_correctly_std',\n",
    "    \n",
    " # additional content_id feature\n",
    " 'content_dup_ratio', \n",
    " 'content_dup_count_ratio',\n",
    " 'bin_0_accu',\n",
    " 'bin_1_accu',\n",
    " 'bin_2_accu',\n",
    " 'bin_3_accu',\n",
    " 'bin_4_accu',\n",
    "    \n",
    "] + ['vec_w2v_' + str(i) for i in range(0, 10)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T06:52:38.531442Z",
     "iopub.status.busy": "2021-01-06T06:52:38.530686Z",
     "iopub.status.idle": "2021-01-06T06:52:38.532927Z",
     "shell.execute_reply": "2021-01-06T06:52:38.533442Z"
    },
    "papermill": {
     "duration": 0.041052,
     "end_time": "2021-01-06T06:52:38.533539",
     "exception": false,
     "start_time": "2021-01-06T06:52:38.492487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_col_mlp = [  \n",
    " 'prior_question_elapsed_time',\n",
    " 'lag_time',\n",
    " 'prior_user_answered_correctly',\n",
    " 'prior_user_score',\n",
    " 'count',\n",
    " 'count_part',\n",
    " 'content_user_cover_ratio',\n",
    " 'first_user_ratio',\n",
    " 'answered_correctly_content',\n",
    " 'answered_correctly_content_first_look',\n",
    " 'fix_answered_correctly_content_first_look',\n",
    " 'part',\n",
    " 'before_lecture',\n",
    " 'L_count', \n",
    " 'R_count', \n",
    " 'prior_L_accu', \n",
    " 'prior_R_accu',\n",
    " 'content_accu_mean',\n",
    " 'content_cumsum_ratio', \n",
    " 'ave_elapsed_time',\n",
    " 'prior_accu_continuous',\n",
    " 'prior_accu_no_continuous',\n",
    " 'dup_time',\n",
    " 'prior_end_to_start', \n",
    " 'content_series_mean',\n",
    " 'tag',\n",
    " 'prior_question_had_explanation',\n",
    " 'lec_num',\n",
    " 'session_time',\n",
    " 'session_count',\n",
    " 'prior_session_time',\n",
    " 'prior_session_prob',\n",
    " 'mean_lag_time',\n",
    " 'lag_user_ave',\n",
    " 'lag_user_p2_ave',\n",
    " 'lag_user_p5_ave',\n",
    " 'lag_c_p2',\n",
    " 'lag_c_p5',\n",
    " 'lag_task',\n",
    " 'dup_ratio',\n",
    " 'count_dif_50_ratio', \n",
    " 'count_dif_75_ratio', \n",
    " 'count_dif_1_ratio',\n",
    " 'difficulty_50_ratio',\n",
    " 'difficulty_75_ratio',\n",
    " 'difficulty_1_ratio',\n",
    " 'dup_row_num',\n",
    "\n",
    " 'prior_L_user_score',\n",
    " 'prior_R_user_score',\n",
    " 'user_score_ratio',\n",
    " 'prior_p2_accu',\n",
    " 'prior_p5_accu',\n",
    "    \n",
    " # lag_u_features\n",
    " 'lag_u_bin_0_accu_mean',\n",
    " 'lag_u_bin_1_accu_mean',\n",
    " 'lag_u_bin_2_accu_mean',\n",
    " 'lag_u_bin_3_accu_mean',\n",
    " 'lag_u_bin_0_count_ratio',\n",
    " 'lag_u_bin_1_count_ratio',\n",
    " 'lag_u_bin_2_count_ratio',\n",
    " 'lag_u_bin_3_count_ratio',\n",
    " 'elp_u_bin_0_accu_mean',\n",
    " 'elp_u_bin_1_accu_mean',\n",
    " 'elp_u_bin_2_accu_mean',\n",
    " 'elp_u_bin_3_accu_mean',\n",
    " 'elp_u_bin_0_count_ratio',\n",
    " 'elp_u_bin_1_count_ratio',\n",
    " 'elp_u_bin_2_count_ratio',\n",
    " 'elp_u_bin_3_count_ratio',\n",
    "    \n",
    " # content * prior_accu\n",
    " 'content_accuracy',\n",
    "    \n",
    " # content * lag\n",
    " 'same_lag_user_content_accuracy',\n",
    "    \n",
    " # ninopy\n",
    " 'content_unacc_user_prior_user_answered_correctly_mean',\n",
    " 'content_unacc_user_prior_user_answered_correctly_std',\n",
    "    \n",
    " # additional content_id feature\n",
    " 'content_dup_ratio', \n",
    " 'content_dup_count_ratio',\n",
    " 'bin_0_accu',\n",
    " 'bin_1_accu',\n",
    " 'bin_2_accu',\n",
    " 'bin_3_accu',\n",
    " 'bin_4_accu',\n",
    "\n",
    "] + ['vec_w2v_' + str(i) for i in range(0, 10)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T06:52:38.594638Z",
     "iopub.status.busy": "2021-01-06T06:52:38.593840Z",
     "iopub.status.idle": "2021-01-06T06:52:38.597000Z",
     "shell.execute_reply": "2021-01-06T06:52:38.597506Z"
    },
    "papermill": {
     "duration": 0.036095,
     "end_time": "2021-01-06T06:52:38.597679",
     "exception": false,
     "start_time": "2021-01-06T06:52:38.561584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['count', 'answered_correctly_cumsum', 'count_part', 'answered_correctly_cumsum_part', 'L_count', 'R_count', 'L_accu_sum', 'R_accu_sum', 'user_score_cumsum', 'first_user_ratio', 'lag_time', 'last_timestamp', 'content_cumsum', 'before_lecture', 'prior_accu_continuous', 'prior_accu_no_continuous', 'last_end_to_start_time', 'last_question_elapsed_time', 'session_time', 'session_first_time', 'session_count', 'session_num', 'session_accu', 'prior_session_prob', 'prior_session_time', 'lag_user', 'lag_user_p2', 'lag_user_p5', 'lag_c', 'lag_c_p2', 'lag_c_p5', 'last_task_container_id', 'lag_task', 'dup_num_2', 'last_bundle_id', 'last_dup_row_num', 'count_dif_50', 'count_dif_75', 'count_dif_1', 'difficulty_50', 'difficulty_75', 'difficulty_1', 'L_score', 'R_score', 'p2_accu_sum', 'p5_accu_sum', 'p2_count', 'p5_count', 'lag_u_bin_0_accu_sum', 'lag_u_bin_1_accu_sum', 'lag_u_bin_2_accu_sum', 'lag_u_bin_3_accu_sum', 'lag_u_bin_0_accu_mean', 'lag_u_bin_1_accu_mean', 'lag_u_bin_2_accu_mean', 'lag_u_bin_3_accu_mean', 'lag_u_bin_0_count', 'lag_u_bin_1_count', 'lag_u_bin_2_count', 'lag_u_bin_3_count', 'elp_u_bin_0_accu_sum', 'elp_u_bin_1_accu_sum', 'elp_u_bin_2_accu_sum', 'elp_u_bin_3_accu_sum', 'elp_u_bin_0_accu_mean', 'elp_u_bin_1_accu_mean', 'elp_u_bin_2_accu_mean', 'elp_u_bin_3_accu_mean', 'elp_u_bin_0_count', 'elp_u_bin_1_count', 'elp_u_bin_2_count', 'elp_u_bin_3_count', 'lag_time_bin', 'elp_time_bin', 'prior_user_answered_correctly_bin', 'prior_answer', 'prior_user_answered_correctly', 'prior_L_accu', 'prior_R_accu', 'prior_user_score', 'prior_L_user_score', 'prior_R_user_score', 'difficulty_50_ratio', 'difficulty_75_ratio', 'difficulty_1_ratio', 'prior_p2_accu', 'prior_p5_accu'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_accu_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.028506,
     "end_time": "2021-01-06T06:52:38.654494",
     "exception": false,
     "start_time": "2021-01-06T06:52:38.625988",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## sparse matrixを使っている特徴量の更新関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T06:52:38.723678Z",
     "iopub.status.busy": "2021-01-06T06:52:38.722914Z",
     "iopub.status.idle": "2021-01-06T06:52:38.725744Z",
     "shell.execute_reply": "2021-01-06T06:52:38.725330Z"
    },
    "papermill": {
     "duration": 0.043149,
     "end_time": "2021-01-06T06:52:38.725828",
     "exception": false,
     "start_time": "2021-01-06T06:52:38.682679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def update_dup_num(test_df, user_accu_dict, dup_time_matrix, user_master, content_master):\n",
    "    \n",
    "    #----------------------------------\n",
    "    # update dup_ratio and dup_time using sparse matrix\n",
    "    #----------------------------------\n",
    "\n",
    "    dup_ratio = np.zeros(len(test_df), dtype=np.float64)\n",
    "    dup_time = np.zeros(len(test_df), dtype=np.float64)\n",
    "\n",
    "    for cnt, row in enumerate(test_df[['user_id', 'content_id', 'content_type_id', 'timestamp']].values):\n",
    "        \n",
    "        user_accu_dict['dup_num_2'].setdefault(row[0], 0)\n",
    "\n",
    "        # 各user/回答contentで既に時間が入っている場合、現timestamp - 過去回答時間を入力\n",
    "        # user_idとcontent_idはuser_masterとcontent_master内でそれぞれ行列番号に変換\n",
    "        if dup_time_matrix[user_master[row[0]], content_master[row[1]]] > 0:\n",
    "            dup_time[cnt] = row[3] - (np.exp(dup_time_matrix[user_master[row[0]], content_master[row[1]]]) - 1)\n",
    "            \n",
    "            # 重複があるたびにカウントアップ\n",
    "            user_accu_dict['dup_num_2'][row[0]] += 1\n",
    "        else:\n",
    "            dup_time[cnt] = 0\n",
    "        \n",
    "        # dup_ratio：重複のあった数/全回答数をユーザー毎にrollingして求める\n",
    "        dup_ratio[cnt] = np.array(user_accu_dict['dup_num_2'][row[0]]) / np.array(user_accu_dict['count'][row[0]])\n",
    "        \n",
    "        # update dup_time matrix：時間を更新する\n",
    "        dup_time_matrix[user_master[row[0]], content_master[row[1]]] = np.log(row[3] + 1)\n",
    "        \n",
    "\n",
    "    df_dup = pd.DataFrame({'dup_time':dup_time, 'dup_ratio':dup_ratio})\n",
    "    test_df = pd.concat([test_df.reset_index(drop=True), df_dup], axis=1)\n",
    "\n",
    "    return test_df, dup_time_matrix, user_accu_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.028651,
     "end_time": "2021-01-06T06:52:38.783356",
     "exception": false,
     "start_time": "2021-01-06T06:52:38.754705",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 特徴量の更新関数\n",
    "- test時点で判明している変数(countなど）は、この時点で更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T06:52:38.861188Z",
     "iopub.status.busy": "2021-01-06T06:52:38.845021Z",
     "iopub.status.idle": "2021-01-06T06:52:39.016800Z",
     "shell.execute_reply": "2021-01-06T06:52:39.016366Z"
    },
    "papermill": {
     "duration": 0.20483,
     "end_time": "2021-01-06T06:52:39.016903",
     "exception": false,
     "start_time": "2021-01-06T06:52:38.812073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def update_test_df(test_df, user_accu_dict, content_dict, tag_matrix, user_master, tag_mat_master, \n",
    "                   content_same_lag_accuracy_dict, content_same_prioraccu_accuracy_dict):\n",
    "    \n",
    "    \n",
    "    # 初期化\n",
    "    user_answer_sum = np.zeros(len(test_df), dtype=np.int32)\n",
    "    user_answer_part_sum = np.zeros(len(test_df), dtype=np.float32)\n",
    "    user_answer_L_sum = np.zeros(len(test_df), dtype=np.float32)\n",
    "    user_answer_R_sum = np.zeros(len(test_df), dtype=np.float32)\n",
    "    user_score_sum = np.zeros(len(test_df), dtype=np.float32)\n",
    "    count = np.zeros(len(test_df), dtype=np.int32)\n",
    "    count_part = np.zeros(len(test_df), dtype=np.int32)\n",
    "    count_L = np.zeros(len(test_df), dtype=np.int32)\n",
    "    count_R = np.zeros(len(test_df), dtype=np.int32)\n",
    "    before_lecture = np.zeros(len(test_df), dtype=np.int8)\n",
    "    first_user_ratio = np.zeros(len(test_df), dtype=np.float32)\n",
    "    content_cumsum_ratio = np.zeros(len(test_df), dtype=np.float32)\n",
    "    prior_accu_continuous = np.zeros(len(test_df), dtype=np.float32)\n",
    "    prior_accu_no_continuous = np.zeros(len(test_df), dtype=np.float32)\n",
    "    prior_user_answered_correctly = np.zeros(len(test_df), dtype=np.float32)\n",
    "    prior_user_score = np.zeros(len(test_df), dtype=np.float32)\n",
    "    prior_L_accu = np.zeros(len(test_df), dtype=np.float32)\n",
    "    prior_R_accu = np.zeros(len(test_df), dtype=np.float32)\n",
    "    \n",
    "    lag_time = np.zeros(len(test_df), dtype=np.float64)\n",
    "    prior_start_end_time = np.zeros(len(test_df), dtype=np.float64)\n",
    "    start_to_start = np.zeros(len(test_df), dtype=np.float64)\n",
    "    lec_num = np.zeros(len(test_df), dtype=np.int16)\n",
    "    \n",
    "    prior_session_time = np.zeros(len(test_df), dtype=np.float64)\n",
    "    session_time = np.zeros(len(test_df), dtype=np.float64)\n",
    "    session_first_time = np.zeros(len(test_df), dtype=np.float64)\n",
    "    session_count = np.zeros(len(test_df), dtype=np.int16)\n",
    "    session_accu = np.zeros(len(test_df), dtype=np.int16)\n",
    "    prior_session_accu = np.zeros(len(test_df), dtype=np.float64)\n",
    "    \n",
    "    lag_user_ave = np.zeros(len(test_df), dtype=np.float32)\n",
    "    lag_user_p2_ave = np.zeros(len(test_df), dtype=np.float32)\n",
    "    lag_user_p5_ave = np.zeros(len(test_df), dtype=np.float32)\n",
    "    lag_c_p2 = np.zeros(len(test_df), dtype=np.int32)\n",
    "    lag_c_p5 = np.zeros(len(test_df), dtype=np.int32)\n",
    "    lag_task = np.zeros(len(test_df), dtype=np.int16)\n",
    "    dup_row_num = np.zeros(len(test_df), dtype=np.int16)\n",
    "    \n",
    "    count_dif_50_ratio = np.zeros(len(test_df), dtype=np.float32)\n",
    "    count_dif_75_ratio = np.zeros(len(test_df), dtype=np.float32)\n",
    "    count_dif_1_ratio = np.zeros(len(test_df), dtype=np.float32)\n",
    "    difficulty_50_ratio = np.zeros(len(test_df), dtype=np.float32)\n",
    "    difficulty_75_ratio = np.zeros(len(test_df), dtype=np.float32)\n",
    "    difficulty_1_ratio = np.zeros(len(test_df), dtype=np.float32)\n",
    "    \n",
    "    prior_L_user_score = np.zeros(len(test_df), dtype=np.float32)\n",
    "    prior_R_user_score = np.zeros(len(test_df), dtype=np.float32)\n",
    "    user_score_ratio = np.zeros(len(test_df), dtype=np.float32)\n",
    "    \n",
    "    prior_p2_accu = np.zeros(len(test_df), dtype=np.float32)\n",
    "    prior_p5_accu = np.zeros(len(test_df), dtype=np.float32)\n",
    "    \n",
    "    # add bin features\n",
    "    lag_u_bin_0_accu_mean = np.zeros(len(test_df), dtype=np.float32)\n",
    "    lag_u_bin_1_accu_mean = np.zeros(len(test_df), dtype=np.float32)\n",
    "    lag_u_bin_2_accu_mean = np.zeros(len(test_df), dtype=np.float32)\n",
    "    lag_u_bin_3_accu_mean = np.zeros(len(test_df), dtype=np.float32)\n",
    "    lag_u_bin_0_count_ratio = np.zeros(len(test_df), dtype=np.float32)\n",
    "    lag_u_bin_1_count_ratio = np.zeros(len(test_df), dtype=np.float32)\n",
    "    lag_u_bin_2_count_ratio = np.zeros(len(test_df), dtype=np.float32)\n",
    "    lag_u_bin_3_count_ratio = np.zeros(len(test_df), dtype=np.float32)\n",
    "\n",
    "    elp_u_bin_0_accu_mean = np.zeros(len(test_df), dtype=np.float32)\n",
    "    elp_u_bin_1_accu_mean = np.zeros(len(test_df), dtype=np.float32)\n",
    "    elp_u_bin_2_accu_mean = np.zeros(len(test_df), dtype=np.float32)\n",
    "    elp_u_bin_3_accu_mean = np.zeros(len(test_df), dtype=np.float32)\n",
    "    elp_u_bin_0_count_ratio = np.zeros(len(test_df), dtype=np.float32)\n",
    "    elp_u_bin_1_count_ratio = np.zeros(len(test_df), dtype=np.float32)\n",
    "    elp_u_bin_2_count_ratio = np.zeros(len(test_df), dtype=np.float32)\n",
    "    elp_u_bin_3_count_ratio = np.zeros(len(test_df), dtype=np.float32)\n",
    "    \n",
    "    content_accuracy = np.zeros(len(test_df), dtype=np.float32)\n",
    "    same_lag_user_content_accuracy = np.zeros(len(test_df), dtype=np.float32)\n",
    "        \n",
    "    \n",
    "    for cnt, row in enumerate(test_df[['user_id', 'part', 'content_id', 'L_R', 'timestamp', 'content_type_id', \n",
    "                                       'prior_question_elapsed_time', 'tag',  'task_container_id', 'prob_difficuly', \n",
    "                                       'bundle_id', 'prior_question_had_explanation']].values):\n",
    "                \n",
    "        # 各種dictの更新\n",
    "        user_accu_dict['answered_correctly_cumsum'].setdefault(row[0], 0)\n",
    "        user_accu_dict['count'].setdefault(row[0], 0)\n",
    "        user_accu_dict['first_user_ratio'].setdefault(row[0], 0) \n",
    "        user_accu_dict['L_accu_sum'].setdefault(row[0], 0)\n",
    "        user_accu_dict['R_accu_sum'].setdefault(row[0], 0)\n",
    "        user_accu_dict['L_count'].setdefault(row[0], 0)\n",
    "        user_accu_dict['R_count'].setdefault(row[0], 0)\n",
    "        user_accu_dict['user_score_cumsum'].setdefault(row[0], 0)\n",
    "        user_accu_dict['before_lecture'].setdefault(row[0], 0)        \n",
    "        user_accu_dict['count_part'].setdefault(tuple(row[0:2]), 0)\n",
    "        user_accu_dict['content_cumsum'].setdefault(row[0], 0)\n",
    "        user_accu_dict['last_timestamp'].setdefault(row[0], 0)\n",
    "        user_accu_dict['lag_time'].setdefault(row[0], np.nan)\n",
    "        user_accu_dict['last_end_to_start_time'].setdefault(row[0], np.nan)\n",
    "                \n",
    "        user_accu_dict['session_time'].setdefault(row[0], np.nan)\n",
    "        user_accu_dict['session_first_time'].setdefault(row[0], 0)\n",
    "        user_accu_dict['session_count'].setdefault(row[0], 0)\n",
    "        user_accu_dict['session_accu'].setdefault(row[0], 0)\n",
    "        user_accu_dict['prior_session_time'].setdefault(row[0], np.nan)\n",
    "        \n",
    "        user_accu_dict['lag_user'].setdefault(row[0], 0)\n",
    "        user_accu_dict['lag_user_p2'].setdefault(row[0], 0)\n",
    "        user_accu_dict['lag_user_p5'].setdefault(row[0], 0)\n",
    "        \n",
    "        user_accu_dict['lag_c'].setdefault(row[0], 0)\n",
    "        user_accu_dict['lag_c_p2'].setdefault(row[0], 0)\n",
    "        user_accu_dict['lag_c_p5'].setdefault(row[0], 0)\n",
    "        \n",
    "        user_accu_dict['last_task_container_id'].setdefault(row[0], 0)\n",
    "        user_accu_dict['lag_task'].setdefault(row[0], 1)\n",
    "\n",
    "        user_accu_dict['prior_user_answered_correctly'].setdefault(row[0], np.nan)\n",
    "        user_accu_dict['prior_user_score'].setdefault(row[0], np.nan)\n",
    "        user_accu_dict['prior_L_accu'].setdefault(row[0], np.nan)\n",
    "        user_accu_dict['prior_R_accu'].setdefault(row[0], np.nan)\n",
    "        user_accu_dict['prior_accu_continuous'].setdefault(row[0], np.nan)\n",
    "        user_accu_dict['prior_accu_no_continuous'].setdefault(row[0], np.nan)\n",
    "        user_accu_dict['prior_session_prob'].setdefault(row[0], np.nan)\n",
    "        user_accu_dict['prior_L_user_score'].setdefault(row[0], 0)\n",
    "        user_accu_dict['prior_R_user_score'].setdefault(row[0], 0)\n",
    "        user_accu_dict['prior_p2_accu'].setdefault(row[0], 0)\n",
    "        user_accu_dict['prior_p5_accu'].setdefault(row[0], 0)\n",
    "        \n",
    "        user_accu_dict['count_dif_50'].setdefault(row[0], 0)\n",
    "        user_accu_dict['count_dif_75'].setdefault(row[0], 0)\n",
    "        user_accu_dict['count_dif_1'].setdefault(row[0], 0)\n",
    "        user_accu_dict['difficulty_50'].setdefault(row[0], 0)\n",
    "        user_accu_dict['difficulty_75'].setdefault(row[0], 0)\n",
    "        user_accu_dict['difficulty_1'].setdefault(row[0], 0)\n",
    "        \n",
    "        user_accu_dict['last_bundle_id'].setdefault(row[0], np.nan)\n",
    "        user_accu_dict['last_dup_row_num'].setdefault(row[0], 0)\n",
    "        \n",
    "        user_accu_dict['L_score'].setdefault(row[0], 0)\n",
    "        user_accu_dict['R_score'].setdefault(row[0], 0)\n",
    "        \n",
    "        user_accu_dict['p2_count'].setdefault(row[0], 0)\n",
    "        user_accu_dict['p5_count'].setdefault(row[0], 0)\n",
    "        \n",
    "        user_accu_dict['p2_accu_sum'].setdefault(row[0], 0)\n",
    "        user_accu_dict['p5_accu_sum'].setdefault(row[0], 0)\n",
    "        \n",
    "        user_accu_dict['difficulty_50_ratio'].setdefault(row[0], 0)\n",
    "        user_accu_dict['difficulty_75_ratio'].setdefault(row[0], 0)\n",
    "        user_accu_dict['difficulty_1_ratio'].setdefault(row[0], 0)\n",
    "        \n",
    "        user_accu_dict['lag_time_bin'].setdefault(row[0], np.nan)\n",
    "        user_accu_dict['elp_time_bin'].setdefault(row[0], np.nan)\n",
    "        user_accu_dict['prior_user_answered_correctly_bin'].setdefault(row[0], np.nan)\n",
    "        user_accu_dict['prior_answer'].setdefault(row[0], 0)\n",
    "        \n",
    "        user_accu_dict['lag_u_bin_0_accu_sum'].setdefault(row[0], 0)\n",
    "        user_accu_dict['lag_u_bin_1_accu_sum'].setdefault(row[0], 0)\n",
    "        user_accu_dict['lag_u_bin_2_accu_sum'].setdefault(row[0], 0) \n",
    "        user_accu_dict['lag_u_bin_3_accu_sum'].setdefault(row[0], 0)\n",
    "        user_accu_dict['lag_u_bin_0_count'].setdefault(row[0], 0)\n",
    "        user_accu_dict['lag_u_bin_1_count'].setdefault(row[0], 0)\n",
    "        user_accu_dict['lag_u_bin_2_count'].setdefault(row[0], 0)\n",
    "        user_accu_dict['lag_u_bin_3_count'].setdefault(row[0], 0)\n",
    "        user_accu_dict['lag_u_bin_0_accu_mean'].setdefault(row[0], np.nan)\n",
    "        user_accu_dict['lag_u_bin_1_accu_mean'].setdefault(row[0], np.nan)\n",
    "        user_accu_dict['lag_u_bin_2_accu_mean'].setdefault(row[0], np.nan) \n",
    "        user_accu_dict['lag_u_bin_3_accu_mean'].setdefault(row[0], np.nan)\n",
    "        \n",
    "        user_accu_dict['elp_u_bin_0_accu_sum'].setdefault(row[0], 0)\n",
    "        user_accu_dict['elp_u_bin_1_accu_sum'].setdefault(row[0], 0)\n",
    "        user_accu_dict['elp_u_bin_2_accu_sum'].setdefault(row[0], 0)\n",
    "        user_accu_dict['elp_u_bin_3_accu_sum'].setdefault(row[0], 0)\n",
    "        user_accu_dict['elp_u_bin_0_count'].setdefault(row[0], 0)\n",
    "        user_accu_dict['elp_u_bin_1_count'].setdefault(row[0], 0)\n",
    "        user_accu_dict['elp_u_bin_2_count'].setdefault(row[0], 0)\n",
    "        user_accu_dict['elp_u_bin_3_count'].setdefault(row[0], 0)\n",
    "        user_accu_dict['elp_u_bin_0_accu_mean'].setdefault(row[0], np.nan)\n",
    "        user_accu_dict['elp_u_bin_1_accu_mean'].setdefault(row[0], np.nan)\n",
    "        user_accu_dict['elp_u_bin_2_accu_mean'].setdefault(row[0], np.nan) \n",
    "        user_accu_dict['elp_u_bin_3_accu_mean'].setdefault(row[0], np.nan)\n",
    "        \n",
    "        \n",
    "        # matrix更新用のuser/tag masterもここで更新する\n",
    "        # 新しいユーザーが来た場合は行列の一番最後の行に入れることにするため、len(user_master)を割り付ける\n",
    "        user_master.setdefault(row[0], len(user_master))\n",
    "        tag_mat_master.setdefault(row[7], 999)\n",
    "        \n",
    "        \n",
    "        #---------------------------------\n",
    "        # update dict before add feature\n",
    "        #---------------------------------\n",
    "        \n",
    "        # timestampが前回と違うとき（＝bundle_idが違う。part6などの同じtimestampで複数問題があるときでも正しく更新するための条件）\n",
    "        if row[4] != user_accu_dict['last_timestamp'][row[0]]:\n",
    "                                    \n",
    "            # 'prior_question_elapsed_time'がnanでない場合、end_to_start_timeの辞書を更新\n",
    "            if row[6] >= 0:\n",
    "                user_accu_dict['last_end_to_start_time'][row[0]] = np.array(user_accu_dict['lag_time'][row[0]]) - np.array(row[6])\n",
    "                \n",
    "            # lag_timeを更新。前回時間からの差分\n",
    "            user_accu_dict['lag_time'][row[0]] = np.array(row[4]) - np.array(user_accu_dict['last_timestamp'][row[0]])\n",
    "                        \n",
    "            # task_containerの差分を更新\n",
    "            user_accu_dict['lag_task'][row[0]] = row[8] - user_accu_dict['last_task_container_id'][row[0]]\n",
    "            user_accu_dict['last_task_container_id'][row[0]] = row[8]\n",
    "            \n",
    "            # timestampが異なるから本来はbundle_idが違うはずなのに、連続して同じbundle_idが来る場合はカウント（同じ問題の連続回答フラグ）\n",
    "            if row[5] == 0:\n",
    "                if row[10] == user_accu_dict['last_bundle_id'][row[0]]:\n",
    "                    user_accu_dict['last_dup_row_num'][row[0]] += 1\n",
    "                else:\n",
    "                    user_accu_dict['last_dup_row_num'][row[0]] = 0\n",
    "            # 辞書更新\n",
    "            user_accu_dict['last_bundle_id'][row[0]] = row[10]\n",
    "\n",
    "        \n",
    "        #---------------------------------\n",
    "        # update tag_num matrix\n",
    "        #---------------------------------\n",
    "        \n",
    "        # もしlectureだった場合、tagと合わせて回数を更新\n",
    "        if row[5] == 1:\n",
    "            tag_matrix[user_master[row[0]], tag_mat_master[row[7]]] += 1\n",
    "                \n",
    "\n",
    "        #---------------------------------\n",
    "        # update without lecture feature\n",
    "        #---------------------------------\n",
    "        \n",
    "        if row[5] == 0:\n",
    "\n",
    "            # update count dict\n",
    "            user_accu_dict['count'][row[0]] += 1\n",
    "            user_accu_dict['count_part'][tuple(row[0:2])] += 1\n",
    "            \n",
    "            # update content_cumsum\n",
    "            #'answered_correctly_content_first_look'はコンテンツの難易度。それをどんどん合計していく（後からcountで割る）\n",
    "            user_accu_dict['content_cumsum'][row[0]] += content_dict['answered_correctly_content_first_look'][row[2]]\n",
    "            \n",
    "            # LもしくはRならcountup\n",
    "            if row[3] == 1:\n",
    "                user_accu_dict['L_count'][row[0]] += 1\n",
    "            else:\n",
    "                user_accu_dict['R_count'][row[0]] += 1\n",
    "            \n",
    "            # part2/5ならcountup\n",
    "            if row[1] == 2:\n",
    "                user_accu_dict['p2_count'][row[0]] += 1\n",
    " \n",
    "            if row[1] == 5:\n",
    "                user_accu_dict['p5_count'][row[0]] += 1\n",
    "                       \n",
    "            # first_user_ratio\n",
    "            # timestampが0のとき(初めてのとき）のみ、初回質問の回答率を付与する（以後ユーザー内での更新無）\n",
    "            if row[4] == 0:\n",
    "                user_accu_dict['first_user_ratio'][row[0]] = content_dict['content_user_cover_ratio'][row[2]]\n",
    "                \n",
    "                \n",
    "            #---------------------------------\n",
    "            # update session feature\n",
    "            #---------------------------------\n",
    "            # lag_timeが小さい(30分以内）場合、session_countを更新する\n",
    "            # lag_timeが大きい場合、session_time(session_first_time - last_timestamp)を求める \n",
    "            # また、session_count/accuを0に更新してから（リスタート）session_starttimeをtimestampに更新する\n",
    "\n",
    "            if user_accu_dict['lag_time'][row[0]] < 3600000 or row[4] == 0:\n",
    "                user_accu_dict['session_count'][row[0]] += 1\n",
    "            else:\n",
    "                if row[4] != user_accu_dict['last_timestamp'][row[0]]:\n",
    "                    user_accu_dict['session_time'][row[0]] = user_accu_dict['last_timestamp'][row[0]] - user_accu_dict['session_first_time'][row[0]]                        \n",
    "                # update count\n",
    "                user_accu_dict['session_count'][row[0]] = 1\n",
    "                user_accu_dict['session_first_time'][row[0]] = row[4]\n",
    "                \n",
    "            #---------------------------------\n",
    "            # update lagtime feature(30分以上はカウント無。part毎でも求める）\n",
    "            #---------------------------------\n",
    "            \n",
    "            if user_accu_dict['lag_time'][row[0]] < 900000:\n",
    "                              \n",
    "                user_accu_dict['lag_user'][row[0]] += user_accu_dict['lag_time'][row[0]]\n",
    "                user_accu_dict['lag_c'][row[0]] += 1\n",
    "            \n",
    "                if row[1] == 2:\n",
    "                    user_accu_dict['lag_user_p2'][row[0]] += user_accu_dict['lag_time'][row[0]]\n",
    "                    user_accu_dict['lag_c_p2'][row[0]] += 1\n",
    "\n",
    "                if row[1] == 5:\n",
    "                    user_accu_dict['lag_user_p5'][row[0]] += user_accu_dict['lag_time'][row[0]]\n",
    "                    user_accu_dict['lag_c_p5'][row[0]] += 1\n",
    "            \n",
    "            \n",
    "            #---------------------------------\n",
    "            # update difficulty feature\n",
    "            #---------------------------------\n",
    "            \n",
    "            # 各難易度に合わせて難易度count更新\n",
    "            if row[9] == '0.5':\n",
    "                user_accu_dict['count_dif_50'][row[0]] += 1\n",
    "                \n",
    "            if row[9] == '0.75':\n",
    "                user_accu_dict['count_dif_75'][row[0]] += 1\n",
    "                \n",
    "            if row[9] == '1.0':\n",
    "                user_accu_dict['count_dif_1'][row[0]] += 1\n",
    "                \n",
    "                \n",
    "            #---------------------------------\n",
    "            # make bin features\n",
    "            #---------------------------------\n",
    "            # 紐づけ用のbin featureを作成する\n",
    "            user_accu_dict['prior_user_answered_correctly_bin'][row[0]] = bin_accuracy(user_accu_dict['prior_user_answered_correctly'][row[0]])\n",
    "            user_accu_dict['lag_time_bin'][row[0]] = bin_lag_time(user_accu_dict['lag_time'][row[0]])\n",
    "            user_accu_dict['elp_time_bin'][row[0]] = bin_elp_time(row[6])\n",
    "            \n",
    "            # dictを更新 (binが無いと作れないのでここで更新)\n",
    "            content_same_lag_accuracy_dict['same_lag_user_content_accuracy'].setdefault(tuple([row[2], user_accu_dict['lag_time_bin'][row[0]]]), np.nan)\n",
    "            content_same_prioraccu_accuracy_dict['same_accu_user_content_accuracy'].setdefault(tuple([row[2], user_accu_dict['prior_user_answered_correctly_bin'][row[0]]]), np.nan)\n",
    "            \n",
    "            \n",
    "            #---------------------------------\n",
    "            # make user_bin features\n",
    "            #---------------------------------\n",
    "            \n",
    "            if user_accu_dict['lag_time_bin'][row[0]] == 0:\n",
    "                user_accu_dict['lag_u_bin_0_count'][row[0]] += 1\n",
    "                \n",
    "            if user_accu_dict['lag_time_bin'][row[0]] == 1:\n",
    "                user_accu_dict['lag_u_bin_1_count'][row[0]] += 1\n",
    "                \n",
    "            if user_accu_dict['lag_time_bin'][row[0]] == 2:\n",
    "                user_accu_dict['lag_u_bin_2_count'][row[0]] += 1\n",
    "                \n",
    "            if user_accu_dict['lag_time_bin'][row[0]] == 3:\n",
    "                user_accu_dict['lag_u_bin_3_count'][row[0]] += 1\n",
    "                \n",
    "                \n",
    "            if user_accu_dict['elp_time_bin'][row[0]] == 0:\n",
    "                user_accu_dict['elp_u_bin_0_count'][row[0]] += 1\n",
    "                \n",
    "            if user_accu_dict['elp_time_bin'][row[0]] == 1:\n",
    "                user_accu_dict['elp_u_bin_1_count'][row[0]] += 1\n",
    "                \n",
    "            if user_accu_dict['elp_time_bin'][row[0]] == 2:\n",
    "                user_accu_dict['elp_u_bin_2_count'][row[0]] += 1\n",
    "                \n",
    "            if user_accu_dict['elp_time_bin'][row[0]] == 3:\n",
    "                user_accu_dict['elp_u_bin_3_count'][row[0]] += 1\n",
    "            \n",
    "            # content_accuracyの入力(content_idとbinで紐づける)\n",
    "            # accuracyはtimestamp0のときにnullにする\n",
    "            #if user_accu_dict['prior_user_answered_correctly_bin'][row[0]] >= 0:\n",
    "            \n",
    "            if row[4] > 0:\n",
    "                content_accuracy[cnt] = content_same_prioraccu_accuracy_dict['same_accu_user_content_accuracy'][\n",
    "                    tuple([row[2], user_accu_dict['prior_user_answered_correctly_bin'][row[0]]])]\n",
    "            else:\n",
    "                content_accuracy[cnt] = np.nan\n",
    "                \n",
    "            same_lag_user_content_accuracy[cnt] = content_same_lag_accuracy_dict['same_lag_user_content_accuracy'][\n",
    "                tuple([row[2], user_accu_dict['lag_time_bin'][row[0]]])]\n",
    "                \n",
    "\n",
    "        #---------------------------------\n",
    "        # add feature\n",
    "        #---------------------------------\n",
    "        \n",
    "        user_answer_sum[cnt] =     user_accu_dict['answered_correctly_cumsum'][row[0]]\n",
    "        count[cnt] =               user_accu_dict['count'][row[0]]\n",
    "        count_part[cnt] =          user_accu_dict['count_part'][tuple(row[0:2])]\n",
    "        count_L[cnt] =             user_accu_dict['L_count'][row[0]]\n",
    "        count_R[cnt] =             user_accu_dict['R_count'][row[0]]\n",
    "        before_lecture[cnt] =      user_accu_dict['before_lecture'][row[0]]\n",
    "        first_user_ratio[cnt] =    user_accu_dict['first_user_ratio'][row[0]]\n",
    "        content_cumsum_ratio[cnt] = np.array(user_accu_dict['content_cumsum'][row[0]]) / np.array(user_accu_dict['count'][row[0]])\n",
    "        prior_accu_continuous[cnt] = user_accu_dict['prior_accu_continuous'][row[0]]\n",
    "        prior_accu_no_continuous[cnt] = user_accu_dict['prior_accu_no_continuous'][row[0]]\n",
    "        \n",
    "        lag_time[cnt] = user_accu_dict['lag_time'][row[0]]\n",
    "        prior_start_end_time[cnt] = user_accu_dict['last_end_to_start_time'][row[0]]\n",
    "        \n",
    "        lec_num[cnt] = tag_matrix[user_master[row[0]], tag_mat_master[row[7]]]\n",
    "        session_time[cnt] = row[4] - user_accu_dict['session_first_time'][row[0]]\n",
    "        prior_session_time[cnt] = user_accu_dict['session_time'][row[0]]\n",
    "        session_count[cnt] = user_accu_dict['session_count'][row[0]]\n",
    "        lag_user_ave[cnt] = np.array(user_accu_dict['lag_user'][row[0]]) / np.array(user_accu_dict['lag_c'][row[0]])\n",
    "        lag_user_p2_ave[cnt] = np.array(user_accu_dict['lag_user_p2'][row[0]]) / np.array(user_accu_dict['lag_c_p2'][row[0]])\n",
    "        lag_user_p5_ave[cnt] = np.array(user_accu_dict['lag_user_p5'][row[0]]) / np.array(user_accu_dict['lag_c_p5'][row[0]])\n",
    "        lag_c_p2[cnt] = user_accu_dict['lag_c_p2'][row[0]]\n",
    "        lag_c_p5[cnt] = user_accu_dict['lag_c_p5'][row[0]]\n",
    "        \n",
    "        lag_task[cnt] = user_accu_dict['lag_task'][row[0]]        \n",
    "        dup_row_num[cnt] = user_accu_dict['last_dup_row_num'][row[0]]\n",
    "        \n",
    "        count_dif_50_ratio[cnt] = np.array(user_accu_dict['count_dif_50'][row[0]]) / np.array(user_accu_dict['count'][row[0]])\n",
    "        count_dif_75_ratio[cnt] = np.array(user_accu_dict['count_dif_75'][row[0]]) / np.array(user_accu_dict['count'][row[0]])\n",
    "        count_dif_1_ratio[cnt] = np.array(user_accu_dict['count_dif_1'][row[0]]) / np.array(user_accu_dict['count'][row[0]])\n",
    "\n",
    "        \n",
    "        # lag_time_bin_features\n",
    "        lag_u_bin_0_accu_mean[cnt] = user_accu_dict['lag_u_bin_0_accu_mean'][row[0]]\n",
    "        lag_u_bin_1_accu_mean[cnt] = user_accu_dict['lag_u_bin_1_accu_mean'][row[0]]\n",
    "        lag_u_bin_2_accu_mean[cnt] = user_accu_dict['lag_u_bin_2_accu_mean'][row[0]]\n",
    "        lag_u_bin_3_accu_mean[cnt] = user_accu_dict['lag_u_bin_3_accu_mean'][row[0]]\n",
    "        \n",
    "        elp_u_bin_0_accu_mean[cnt] = user_accu_dict['elp_u_bin_0_accu_mean'][row[0]]\n",
    "        elp_u_bin_1_accu_mean[cnt] = user_accu_dict['elp_u_bin_1_accu_mean'][row[0]]\n",
    "        elp_u_bin_2_accu_mean[cnt] = user_accu_dict['elp_u_bin_2_accu_mean'][row[0]]\n",
    "        elp_u_bin_3_accu_mean[cnt] = user_accu_dict['elp_u_bin_3_accu_mean'][row[0]]\n",
    "        \n",
    "        lag_u_bin_0_count_ratio[cnt] = np.array(user_accu_dict['lag_u_bin_0_count'][row[0]]) / np.array(user_accu_dict['count'][row[0]])\n",
    "        lag_u_bin_1_count_ratio[cnt] = np.array(user_accu_dict['lag_u_bin_1_count'][row[0]]) / np.array(user_accu_dict['count'][row[0]])\n",
    "        lag_u_bin_2_count_ratio[cnt] = np.array(user_accu_dict['lag_u_bin_2_count'][row[0]]) / np.array(user_accu_dict['count'][row[0]])\n",
    "        lag_u_bin_3_count_ratio[cnt] = np.array(user_accu_dict['lag_u_bin_3_count'][row[0]]) / np.array(user_accu_dict['count'][row[0]])\n",
    "        \n",
    "        elp_u_bin_0_count_ratio[cnt] = np.array(user_accu_dict['elp_u_bin_0_count'][row[0]]) / np.array(user_accu_dict['count'][row[0]])\n",
    "        elp_u_bin_1_count_ratio[cnt] = np.array(user_accu_dict['elp_u_bin_1_count'][row[0]]) / np.array(user_accu_dict['count'][row[0]])\n",
    "        elp_u_bin_2_count_ratio[cnt] = np.array(user_accu_dict['elp_u_bin_2_count'][row[0]]) / np.array(user_accu_dict['count'][row[0]])\n",
    "        elp_u_bin_3_count_ratio[cnt] = np.array(user_accu_dict['elp_u_bin_3_count'][row[0]]) / np.array(user_accu_dict['count'][row[0]])\n",
    "        \n",
    "          \n",
    "                  \n",
    "        # timestamp=0ならnanにするものたち\n",
    "        if row[4] != 0:\n",
    "            \n",
    "            prior_session_accu[cnt] = user_accu_dict['prior_session_prob'][row[0]]\n",
    "            \n",
    "            prior_user_answered_correctly[cnt] = user_accu_dict['prior_user_answered_correctly'][row[0]]\n",
    "            prior_user_score[cnt] = user_accu_dict['prior_user_score'][row[0]]\n",
    "            prior_L_accu[cnt] = user_accu_dict['prior_L_accu'][row[0]]\n",
    "            prior_R_accu[cnt] = user_accu_dict['prior_R_accu'][row[0]]\n",
    "            \n",
    "            prior_L_user_score[cnt] = user_accu_dict['prior_L_user_score'][row[0]]\n",
    "            prior_R_user_score[cnt] = user_accu_dict['prior_R_user_score'][row[0]]\n",
    "            \n",
    "            difficulty_50_ratio[cnt] = user_accu_dict['difficulty_50_ratio'][row[0]]\n",
    "            difficulty_75_ratio[cnt] = user_accu_dict['difficulty_75_ratio'][row[0]]\n",
    "            difficulty_1_ratio[cnt] = user_accu_dict['difficulty_1_ratio'][row[0]]\n",
    "            \n",
    "            prior_p2_accu[cnt] = user_accu_dict['prior_p2_accu'][row[0]]\n",
    "            prior_p5_accu[cnt] = user_accu_dict['prior_p5_accu'][row[0]]\n",
    "            \n",
    "            lag_u_bin_0_accu_mean[cnt] = user_accu_dict['lag_u_bin_0_accu_mean'][row[0]]\n",
    "            lag_u_bin_1_accu_mean[cnt] = user_accu_dict['lag_u_bin_1_accu_mean'][row[0]]\n",
    "            lag_u_bin_2_accu_mean[cnt] = user_accu_dict['lag_u_bin_2_accu_mean'][row[0]]\n",
    "            lag_u_bin_3_accu_mean[cnt] = user_accu_dict['lag_u_bin_3_accu_mean'][row[0]]\n",
    "\n",
    "            elp_u_bin_0_accu_mean[cnt] = user_accu_dict['elp_u_bin_0_accu_mean'][row[0]]\n",
    "            elp_u_bin_1_accu_mean[cnt] = user_accu_dict['elp_u_bin_1_accu_mean'][row[0]]\n",
    "            elp_u_bin_2_accu_mean[cnt] = user_accu_dict['elp_u_bin_2_accu_mean'][row[0]]\n",
    "            elp_u_bin_3_accu_mean[cnt] = user_accu_dict['elp_u_bin_3_accu_mean'][row[0]]\n",
    "            \n",
    "        else:\n",
    "            prior_L_user_score[cnt] = np.nan\n",
    "            prior_R_user_score[cnt] = np.nan\n",
    "            \n",
    "            difficulty_50_ratio[cnt] = np.nan\n",
    "            difficulty_75_ratio[cnt] = np.nan\n",
    "            difficulty_1_ratio[cnt] = np.nan\n",
    "            \n",
    "            prior_session_accu[cnt] = np.nan\n",
    "            \n",
    "            prior_user_answered_correctly[cnt] = np.nan\n",
    "            prior_user_score[cnt] = np.nan\n",
    "            prior_L_accu[cnt] = np.nan\n",
    "            prior_R_accu[cnt] = np.nan\n",
    "            prior_p2_accu[cnt] = np.nan\n",
    "            prior_p5_accu[cnt] = np.nan\n",
    "            \n",
    "            lag_u_bin_0_accu_mean[cnt] = np.nan\n",
    "            lag_u_bin_1_accu_mean[cnt] = np.nan\n",
    "            lag_u_bin_2_accu_mean[cnt] = np.nan\n",
    "            lag_u_bin_3_accu_mean[cnt] = np.nan\n",
    "\n",
    "            elp_u_bin_0_accu_mean[cnt] = np.nan\n",
    "            elp_u_bin_1_accu_mean[cnt] = np.nan\n",
    "            elp_u_bin_2_accu_mean[cnt] = np.nan\n",
    "            elp_u_bin_3_accu_mean[cnt] = np.nan\n",
    "        \n",
    "        \n",
    "        #---------------------------------\n",
    "        # update dict after add feature\n",
    "        #---------------------------------\n",
    "        \n",
    "        # update before_lecture\n",
    "        # timestampが変わらない場合はbefore_lectureは更新しない\n",
    "        if row[4] != user_accu_dict['last_timestamp'][row[0]]:\n",
    "            user_accu_dict['before_lecture'][row[0]] = 0\n",
    "                \n",
    "        # update last timestamp\n",
    "        user_accu_dict['last_timestamp'][row[0]] = row[4]\n",
    "        \n",
    "    \n",
    "    user_score_df = pd.DataFrame({'prior_user_answered_correctly': prior_user_answered_correctly,\n",
    "                                  'prior_user_score': prior_user_score,\n",
    "                                  'prior_L_accu': prior_L_accu,\n",
    "                                  'prior_R_accu': prior_R_accu,\n",
    "                                  'count': count,\n",
    "                                  'count_part': count_part,\n",
    "                                  'L_count': count_L,\n",
    "                                  'R_count': count_R,\n",
    "                                  'before_lecture': before_lecture,\n",
    "                                  'lag_time':lag_time,\n",
    "                                  'first_user_ratio':first_user_ratio,\n",
    "                                  'prior_accu_continuous':prior_accu_continuous,\n",
    "                                  'prior_accu_no_continuous':prior_accu_no_continuous,\n",
    "                                  'content_cumsum_ratio':content_cumsum_ratio,\n",
    "                                  'prior_end_to_start':prior_start_end_time,\n",
    "                                  'start_to_start':start_to_start,\n",
    "                                  \n",
    "                                  'lec_num':lec_num,\n",
    "                                  \n",
    "                                  'session_time':session_time,\n",
    "                                  'prior_session_time':prior_session_time,\n",
    "                                  'session_count':session_count,\n",
    "                                  'prior_session_prob':prior_session_accu,\n",
    "                                  'lag_user_ave':lag_user_ave,\n",
    "                                  'lag_user_p2_ave':lag_user_p2_ave,\n",
    "                                  'lag_user_p5_ave':lag_user_p5_ave,\n",
    "                                  'lag_c_p2':lag_c_p2,\n",
    "                                  'lag_c_p5':lag_c_p5,\n",
    "                                  \n",
    "                                  'count_dif_50_ratio':count_dif_50_ratio,\n",
    "                                  'count_dif_75_ratio':count_dif_75_ratio,\n",
    "                                  'count_dif_1_ratio':count_dif_1_ratio,\n",
    "                                  'difficulty_50_ratio':difficulty_50_ratio,\n",
    "                                  'difficulty_75_ratio':difficulty_75_ratio,\n",
    "                                  'difficulty_1_ratio':difficulty_1_ratio,\n",
    "                                  \n",
    "                                  'prior_L_user_score':prior_L_user_score,\n",
    "                                  'prior_R_user_score':prior_R_user_score,\n",
    "                                  \n",
    "                                  'lag_task':lag_task,\n",
    "                                  'dup_row_num':dup_row_num,\n",
    "                                  'prior_p2_accu':prior_p2_accu,\n",
    "                                  'prior_p5_accu':prior_p5_accu,\n",
    "                                  \n",
    "                                  'lag_u_bin_0_accu_mean':lag_u_bin_0_accu_mean,\n",
    "                                  'lag_u_bin_1_accu_mean':lag_u_bin_1_accu_mean,\n",
    "                                  'lag_u_bin_2_accu_mean':lag_u_bin_2_accu_mean,\n",
    "                                  'lag_u_bin_3_accu_mean':lag_u_bin_3_accu_mean,\n",
    "                                  \n",
    "                                  'lag_u_bin_0_count_ratio':lag_u_bin_0_count_ratio,\n",
    "                                  'lag_u_bin_1_count_ratio':lag_u_bin_1_count_ratio,\n",
    "                                  'lag_u_bin_2_count_ratio':lag_u_bin_2_count_ratio,\n",
    "                                  'lag_u_bin_3_count_ratio':lag_u_bin_3_count_ratio,\n",
    "                                  \n",
    "                                  'elp_u_bin_0_accu_mean':elp_u_bin_0_accu_mean,\n",
    "                                  'elp_u_bin_1_accu_mean':elp_u_bin_1_accu_mean,\n",
    "                                  'elp_u_bin_2_accu_mean':elp_u_bin_2_accu_mean,\n",
    "                                  'elp_u_bin_3_accu_mean':elp_u_bin_3_accu_mean,\n",
    "                                  \n",
    "                                  'elp_u_bin_0_count_ratio':elp_u_bin_0_count_ratio,\n",
    "                                  'elp_u_bin_1_count_ratio':elp_u_bin_1_count_ratio,\n",
    "                                  'elp_u_bin_2_count_ratio':elp_u_bin_2_count_ratio,\n",
    "                                  'elp_u_bin_3_count_ratio':elp_u_bin_3_count_ratio,\n",
    "                                  \n",
    "                                  'content_accuracy':content_accuracy,\n",
    "                                  'same_lag_user_content_accuracy':same_lag_user_content_accuracy,\n",
    "                              })\n",
    "    \n",
    "   \n",
    "    # add user_score_ratio\n",
    "    user_score_df['user_score_ratio'] = np.array(user_score_df['prior_L_user_score']) / np.array(user_score_df['prior_R_user_score'])\n",
    "    \n",
    "    test_df = pd.concat([test_df.reset_index(drop=True), \n",
    "                         user_score_df[['count',\n",
    "                                     'count_part',\n",
    "                                     'L_count',\n",
    "                                     'R_count',\n",
    "                                     'prior_user_answered_correctly',\n",
    "                                     'prior_user_score',\n",
    "                                     'prior_L_accu',\n",
    "                                     'prior_R_accu',\n",
    "                                     'before_lecture',\n",
    "                                     'lag_time',\n",
    "                                     'first_user_ratio',\n",
    "                                     'content_cumsum_ratio',\n",
    "                                     'prior_accu_continuous',\n",
    "                                     'prior_accu_no_continuous',\n",
    "                                     'prior_end_to_start',\n",
    "                                     'lec_num',\n",
    "                                     'session_time',\n",
    "                                     'prior_session_time',\n",
    "                                     'session_count',\n",
    "                                     'prior_session_prob',\n",
    "                                     'lag_user_ave',\n",
    "                                     'lag_user_p2_ave',\n",
    "                                     'lag_user_p5_ave',\n",
    "                                     'lag_c_p2',\n",
    "                                     'lag_c_p5',\n",
    "                                     'lag_task',\n",
    "                                     'dup_row_num',\n",
    "                                     'count_dif_50_ratio', \n",
    "                                     'count_dif_75_ratio', \n",
    "                                     'count_dif_1_ratio',\n",
    "                                     'difficulty_50_ratio',\n",
    "                                     'difficulty_75_ratio',\n",
    "                                     'difficulty_1_ratio',\n",
    "                                     'prior_L_user_score',\n",
    "                                     'prior_R_user_score',\n",
    "                                     'user_score_ratio',\n",
    "                                     'prior_p2_accu',\n",
    "                                     'prior_p5_accu',\n",
    "                                     \n",
    "                                     # lag_time_bin_features\n",
    "                                     'lag_u_bin_0_accu_mean',\n",
    "                                     'lag_u_bin_1_accu_mean',\n",
    "                                     'lag_u_bin_2_accu_mean',\n",
    "                                     'lag_u_bin_3_accu_mean',\n",
    "                                        \n",
    "                                     'lag_u_bin_0_count_ratio',\n",
    "                                     'lag_u_bin_1_count_ratio',\n",
    "                                     'lag_u_bin_2_count_ratio',\n",
    "                                     'lag_u_bin_3_count_ratio',\n",
    "                                        \n",
    "                                     'elp_u_bin_0_accu_mean',\n",
    "                                     'elp_u_bin_1_accu_mean',\n",
    "                                     'elp_u_bin_2_accu_mean',\n",
    "                                     'elp_u_bin_3_accu_mean',\n",
    "                                        \n",
    "                                     'elp_u_bin_0_count_ratio',\n",
    "                                     'elp_u_bin_1_count_ratio',\n",
    "                                     'elp_u_bin_2_count_ratio',\n",
    "                                     'elp_u_bin_3_count_ratio',\n",
    "                                        \n",
    "                                     'content_accuracy',\n",
    "                                     'same_lag_user_content_accuracy',\n",
    "                                                                                \n",
    "                                    ]]], axis=1)\n",
    "\n",
    "    return test_df, user_accu_dict, tag_matrix, user_master, tag_mat_master, content_same_prioraccu_accuracy_dict, content_same_lag_accuracy_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.028863,
     "end_time": "2021-01-06T06:52:39.074798",
     "exception": false,
     "start_time": "2021-01-06T06:52:39.045935",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 辞書の更新関数（前問の回答をもとに更新する辞書）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T06:52:39.161224Z",
     "iopub.status.busy": "2021-01-06T06:52:39.145634Z",
     "iopub.status.idle": "2021-01-06T06:52:39.184068Z",
     "shell.execute_reply": "2021-01-06T06:52:39.184525Z"
    },
    "papermill": {
     "duration": 0.081083,
     "end_time": "2021-01-06T06:52:39.184626",
     "exception": false,
     "start_time": "2021-01-06T06:52:39.103543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def update_dict(test_df, user_accu_dict, answer_score_dict):\n",
    "    \n",
    "    for cnt, row in enumerate(test_df[['user_id', 'part', 'content_id', 'user_answer', \n",
    "                                       'answered_correctly', 'content_type_id', 'L_R', 'timestamp', 'prob_difficuly']].values):\n",
    "                \n",
    "        \n",
    "        if row[5] == 0:\n",
    "            \n",
    "            # answer_score_dictは新しいcontent*選択肢の組み合わせが入る可能性があるのでここで更新\n",
    "            answer_score_dict['answer_score'].setdefault(tuple(row[2:4]), 0.5)\n",
    "            \n",
    "            \n",
    "            # answer_scoreを取得\n",
    "            get_answer_score = answer_score_dict['answer_score'][tuple(row[2:4])]\n",
    "            \n",
    "            \n",
    "            #----------------------------------\n",
    "            # update dict\n",
    "            #----------------------------------\n",
    "            \n",
    "            # ユーザー正答率   \n",
    "            user_accu_dict['answered_correctly_cumsum'][row[0]] += row[4]          \n",
    "            \n",
    "            # L/R正解追加\n",
    "            if row[6] == 1:\n",
    "                user_accu_dict['L_accu_sum'][row[0]] += row[4]\n",
    "                user_accu_dict['L_score'][row[0]] += get_answer_score\n",
    "            else:\n",
    "                user_accu_dict['R_accu_sum'][row[0]] += row[4]\n",
    "                user_accu_dict['R_score'][row[0]] += get_answer_score\n",
    "            \n",
    "            # 連続正解:正しい場合は+1を追加し続け, 間違っていたら0に戻す\n",
    "            if row[4] == 1:\n",
    "                user_accu_dict['prior_accu_continuous'][row[0]] += 1\n",
    "                user_accu_dict['prior_accu_no_continuous'][row[0]] = 0\n",
    "            else:\n",
    "                user_accu_dict['prior_accu_continuous'][row[0]] = 0\n",
    "                user_accu_dict['prior_accu_no_continuous'][row[0]] += 1\n",
    "            \n",
    "            # user_scoreの追加\n",
    "            user_accu_dict['user_score_cumsum'][row[0]] += get_answer_score\n",
    "            \n",
    "            # session（30分以上のlag_timeがない）内の回答ならカウントアップ\n",
    "            if user_accu_dict['lag_time'][row[0]] < 3600000 or row[7] == 0:\n",
    "                user_accu_dict['session_accu'][row[0]] += row[4]\n",
    "            else:\n",
    "                # もしlag_timeの差分が大きい場合は0に更新してからカウントアップ\n",
    "                user_accu_dict['session_accu'][row[0]] = 0\n",
    "                user_accu_dict['session_accu'][row[0]] += row[4]\n",
    "            \n",
    "            # part2/5\n",
    "            if row[1] == 2:\n",
    "                user_accu_dict['p2_accu_sum'][row[0]] += row[4]\n",
    "                \n",
    "            if row[1] == 5:\n",
    "                user_accu_dict['p5_accu_sum'][row[0]] += row[4]\n",
    "            \n",
    "            # difficulty\n",
    "            if row[8] == '0.5':\n",
    "                user_accu_dict['difficulty_50'][row[0]] += row[4]\n",
    "                \n",
    "            if row[8] == '0.75':\n",
    "                user_accu_dict['difficulty_75'][row[0]] += row[4]\n",
    "                \n",
    "            if row[8] == '1.0':\n",
    "                user_accu_dict['difficulty_1'][row[0]] += row[4]\n",
    "                \n",
    "            #---------------------------------\n",
    "            # make user_bin accu features\n",
    "            #---------------------------------\n",
    "            \n",
    "            if user_accu_dict['lag_time_bin'][row[0]] == 0:\n",
    "                user_accu_dict['lag_u_bin_0_accu_sum'][row[0]] += row[4]\n",
    "                \n",
    "            if user_accu_dict['lag_time_bin'][row[0]] == 1:\n",
    "                user_accu_dict['lag_u_bin_1_accu_sum'][row[0]] += row[4]\n",
    "                \n",
    "            if user_accu_dict['lag_time_bin'][row[0]] == 2:\n",
    "                user_accu_dict['lag_u_bin_2_accu_sum'][row[0]] += row[4]\n",
    "                \n",
    "            if user_accu_dict['lag_time_bin'][row[0]] == 3:\n",
    "                user_accu_dict['lag_u_bin_3_accu_sum'][row[0]] += row[4]\n",
    "                \n",
    "            # elapse_timeは前問の時間のため、前問の正解を紐づける\n",
    "            if user_accu_dict['elp_time_bin'][row[0]] == 0:\n",
    "                user_accu_dict['elp_u_bin_0_accu_sum'][row[0]] += user_accu_dict['prior_answer'][row[0]]\n",
    "                \n",
    "            if user_accu_dict['elp_time_bin'][row[0]] == 1:\n",
    "                user_accu_dict['elp_u_bin_1_accu_sum'][row[0]] += user_accu_dict['prior_answer'][row[0]]\n",
    "                \n",
    "            if user_accu_dict['elp_time_bin'][row[0]] == 2:\n",
    "                user_accu_dict['elp_u_bin_2_accu_sum'][row[0]] += user_accu_dict['prior_answer'][row[0]]\n",
    "                \n",
    "            if user_accu_dict['elp_time_bin'][row[0]] == 3:\n",
    "                user_accu_dict['elp_u_bin_3_accu_sum'][row[0]] += user_accu_dict['prior_answer'][row[0]]\n",
    "                \n",
    "            # 全問の正解を保存\n",
    "            user_accu_dict['prior_answer'][row[0]] = row[4]\n",
    "                            \n",
    "                \n",
    "        else:\n",
    "            # before_lesson\n",
    "            user_accu_dict['before_lecture'][row[0]] = 1\n",
    "            \n",
    "        #----------------------------------\n",
    "        # update prior prob features\n",
    "        #----------------------------------\n",
    "        # update prior features\n",
    "        # prob系の変数は、前回回答の答えが得られた後に更新する\n",
    "        # countは前問時点のcountが入るので、回答数とcountは揃う\n",
    "        user_accu_dict['prior_user_answered_correctly'][row[0]] = np.array(user_accu_dict['answered_correctly_cumsum'][row[0]]) / np.array(user_accu_dict['count'][row[0]])\n",
    "        user_accu_dict['prior_user_score'][row[0]] = np.array(user_accu_dict['user_score_cumsum'][row[0]]) / np.array(user_accu_dict['count'][row[0]])\n",
    "        user_accu_dict['prior_L_accu'][row[0]] = np.array(user_accu_dict['L_accu_sum'][row[0]]) / np.array( user_accu_dict['L_count'][row[0]])\n",
    "        user_accu_dict['prior_R_accu'][row[0]] = np.array(user_accu_dict['R_accu_sum'][row[0]]) / np.array( user_accu_dict['R_count'][row[0]])\n",
    "        user_accu_dict['prior_session_prob'][row[0]] = np.array(user_accu_dict['session_accu'][row[0]]) / np.array(user_accu_dict['session_count'][row[0]])\n",
    "        user_accu_dict['prior_L_user_score'][row[0]] = np.array(user_accu_dict['L_score'][row[0]]) / np.array(user_accu_dict['L_count'][row[0]])\n",
    "        user_accu_dict['prior_R_user_score'][row[0]] = np.array(user_accu_dict['R_score'][row[0]]) / np.array(user_accu_dict['R_count'][row[0]])\n",
    "        user_accu_dict['difficulty_50_ratio'][row[0]] = np.array(user_accu_dict['difficulty_50'][row[0]]) / np.array(user_accu_dict['count_dif_50'][row[0]])\n",
    "        user_accu_dict['difficulty_75_ratio'][row[0]] = np.array(user_accu_dict['difficulty_75'][row[0]]) / np.array(user_accu_dict['count_dif_75'][row[0]])\n",
    "        user_accu_dict['difficulty_1_ratio'][row[0]] = np.array(user_accu_dict['difficulty_1'][row[0]]) / np.array(user_accu_dict['count_dif_1'][row[0]])\n",
    "        user_accu_dict['prior_p2_accu'][row[0]] = np.array(user_accu_dict['p2_accu_sum'][row[0]]) / np.array(user_accu_dict['p2_count'][row[0]])\n",
    "        user_accu_dict['prior_p5_accu'][row[0]] = np.array(user_accu_dict['p5_accu_sum'][row[0]]) / np.array(user_accu_dict['p5_count'][row[0]])\n",
    "        \n",
    "        # lag_time_bin\n",
    "        user_accu_dict['lag_u_bin_0_accu_mean'][row[0]] = np.array(user_accu_dict['lag_u_bin_0_accu_sum'][row[0]]) / np.array(user_accu_dict['lag_u_bin_0_count'][row[0]])\n",
    "        user_accu_dict['lag_u_bin_1_accu_mean'][row[0]] = np.array(user_accu_dict['lag_u_bin_1_accu_sum'][row[0]]) / np.array(user_accu_dict['lag_u_bin_1_count'][row[0]])\n",
    "        user_accu_dict['lag_u_bin_2_accu_mean'][row[0]] = np.array(user_accu_dict['lag_u_bin_2_accu_sum'][row[0]]) / np.array(user_accu_dict['lag_u_bin_2_count'][row[0]])\n",
    "        user_accu_dict['lag_u_bin_3_accu_mean'][row[0]] = np.array(user_accu_dict['lag_u_bin_3_accu_sum'][row[0]]) / np.array(user_accu_dict['lag_u_bin_3_count'][row[0]])\n",
    "        \n",
    "        user_accu_dict['elp_u_bin_0_accu_mean'][row[0]] = np.array(user_accu_dict['elp_u_bin_0_accu_sum'][row[0]]) / np.array(user_accu_dict['elp_u_bin_0_count'][row[0]])\n",
    "        user_accu_dict['elp_u_bin_1_accu_mean'][row[0]] = np.array(user_accu_dict['elp_u_bin_1_accu_sum'][row[0]]) / np.array(user_accu_dict['elp_u_bin_1_count'][row[0]])\n",
    "        user_accu_dict['elp_u_bin_2_accu_mean'][row[0]] = np.array(user_accu_dict['elp_u_bin_2_accu_sum'][row[0]]) / np.array(user_accu_dict['elp_u_bin_2_count'][row[0]])\n",
    "        user_accu_dict['elp_u_bin_3_accu_mean'][row[0]] = np.array(user_accu_dict['elp_u_bin_3_accu_sum'][row[0]]) / np.array(user_accu_dict['elp_u_bin_3_count'][row[0]])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.028826,
     "end_time": "2021-01-06T06:52:39.242550",
     "exception": false,
     "start_time": "2021-01-06T06:52:39.213724",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## validationかどうかの確認\n",
    "- validationで確認したい場合はvalidation_flgをTrueにする\n",
    "- 本番で回すときはFalseにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T06:52:39.311001Z",
     "iopub.status.busy": "2021-01-06T06:52:39.310474Z",
     "iopub.status.idle": "2021-01-06T06:52:39.345401Z",
     "shell.execute_reply": "2021-01-06T06:52:39.346117Z"
    },
    "papermill": {
     "duration": 0.074764,
     "end_time": "2021-01-06T06:52:39.346261",
     "exception": false,
     "start_time": "2021-01-06T06:52:39.271497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_header = pd.read_csv('../input/riiid-test-answer-prediction/train.csv', nrows = 1)\n",
    "\n",
    "if use_train:\n",
    "    # simulation data\n",
    "    #train_samp = pd.read_csv('../input/riiid-test-answer-prediction/train.csv', skiprows=77000, nrows = 2000)\n",
    "    train_samp = pd.read_csv('../input/riiid-test-answer-prediction/train.csv', skiprows=100000, nrows = 100)\n",
    "    #train_samp = pd.read_csv('../input/riiid-test-answer-prediction/train.csv', nrows = 1000)\n",
    "    train_samp.columns = train_header.columns\n",
    "    iter_test = Iter_Valid(train_samp,max_user=1)\n",
    "    predicted = []\n",
    "    def set_predict(df):\n",
    "        predicted.append(df)\n",
    "else:\n",
    "    import riiideducation\n",
    "    env = riiideducation.make_env()\n",
    "    iter_test = env.iter_test()\n",
    "    set_predict = env.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T06:52:39.408228Z",
     "iopub.status.busy": "2021-01-06T06:52:39.407329Z",
     "iopub.status.idle": "2021-01-06T06:52:40.796014Z",
     "shell.execute_reply": "2021-01-06T06:52:40.795470Z"
    },
    "papermill": {
     "duration": 1.420568,
     "end_time": "2021-01-06T06:52:40.796133",
     "exception": false,
     "start_time": "2021-01-06T06:52:39.375565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start batch\n",
      "batch end: 0.838\n",
      "batch end: 1.009\n",
      "batch end: 1.186\n",
      "batch end: 1.367\n",
      "CPU times: user 849 ms, sys: 40.3 ms, total: 889 ms\n",
      "Wall time: 1.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# set df\n",
    "previous_test_df = None\n",
    "\n",
    "# set time\n",
    "start = time.time()\n",
    "\n",
    "print('start batch')\n",
    "\n",
    "\n",
    "contents_use_col = ['answered_correctly_content',\n",
    "                    'content_user_cover_ratio',\n",
    "                    'answered_correctly_content_first_look',\n",
    "                    'fix_answered_correctly_content_first_look',\n",
    "                    'content_accu_mean',\n",
    "                    'ave_elapsed_time',\n",
    "                    'content_series_mean',\n",
    "                    'mean_lag_time',\n",
    "                    \n",
    "                     # lag\n",
    "                     'content_lag_count_dist_0',\n",
    "                     'content_lag_count_dist_1',\n",
    "                     'content_lag_count_dist_2',\n",
    "                     'content_lag_count_dist_3',\n",
    "                     'same_lagbin_content_acc_mean_0',\n",
    "                     'same_lagbin_content_acc_mean_1',\n",
    "                     'same_lagbin_content_acc_mean_2',\n",
    "                     'same_lagbin_content_acc_mean_3',\n",
    "\n",
    "                     # elp\n",
    "                     'content_elp_count_dist_0',\n",
    "                     'content_elp_count_dist_1',\n",
    "                     'content_elp_count_dist_2',\n",
    "                     'content_elp_count_dist_3',\n",
    "                     'same_elpbin_content_acc_mean_0',\n",
    "                     'same_elpbin_content_acc_mean_1',\n",
    "                     'same_elpbin_content_acc_mean_2',\n",
    "                     'same_elpbin_content_acc_mean_3',\n",
    "\n",
    "                     # acc\n",
    "                     'content_bin_count_ratio_0',\n",
    "                     'content_bin_count_ratio_1',\n",
    "                     'content_bin_count_ratio_2',\n",
    "                     'content_bin_count_ratio_3',\n",
    "                     'same_prioracbin_content_acc_mean_0',\n",
    "                     'same_prioracbin_content_acc_mean_1',\n",
    "                     'same_prioracbin_content_acc_mean_2',\n",
    "                     'same_prioracbin_content_acc_mean_3',\n",
    "                    \n",
    "                     # ninopy content features\n",
    "                     'content_unacc_user_prior_user_answered_correctly_mean',\n",
    "                     'content_unacc_user_prior_user_answered_correctly_std',\n",
    "                    \n",
    "                     # additinal features\n",
    "                     'content_dup_ratio', \n",
    "                     'content_dup_count_ratio',\n",
    "                     'bin_0_accu',\n",
    "                     'bin_1_accu',\n",
    "                     'bin_2_accu',\n",
    "                     'bin_3_accu',\n",
    "                     'bin_4_accu',\n",
    "                    \n",
    "                   ] + ['vec_w2v_' + str(i) for i in range(0, 10)]\n",
    "\n",
    "# debug用(sub前に推論DMの中身を確認する時に利用)\n",
    "all_test = pd.DataFrame()\n",
    "\n",
    "\n",
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "    \n",
    "    if previous_test_df is not None:\n",
    "        \n",
    "        # Get prior features\n",
    "        previous_test_df['answered_correctly'] = eval(test_df['prior_group_answers_correct'].iloc[0])\n",
    "        previous_test_df['user_answer'] = eval(test_df['prior_group_responses'].iloc[0])\n",
    "        \n",
    "        \n",
    "        # update dict\n",
    "        update_dict(previous_test_df, user_accu_dict, answer_score_dict)\n",
    "        \n",
    "        test_df = pd.concat([test_df.reset_index(drop=True), \n",
    "                             questions.reindex(test_df['content_id'].values).reset_index(drop=True)], axis=1)\n",
    "        previous_test_df = test_df.copy()\n",
    "        \n",
    "    else: \n",
    "        test_df = pd.concat([test_df.reset_index(drop=True), \n",
    "                             questions.reindex(test_df['content_id'].values).reset_index(drop=True)], axis=1)\n",
    "        \n",
    "        previous_test_df = test_df.copy() \n",
    "        \n",
    "    # make features\n",
    "    test_df, user_accu_dict, tag_matrix, user_master, tag_mat_master, \\\n",
    "    content_same_prioraccu_accuracy_dict, content_same_lag_accuracy_dict = update_test_df(\n",
    "        test_df, user_accu_dict, content_dict, tag_matrix, user_master, tag_mat_master, \n",
    "        content_same_lag_accuracy_dict, content_same_prioraccu_accuracy_dict)\n",
    "    \n",
    "    \n",
    "    # extract questions data\n",
    "    test_df = test_df.loc[test_df['content_type_id'] == 0]\n",
    "    test_df['prior_question_had_explanation'] = test_df['prior_question_had_explanation'].astype('float32')\n",
    "    \n",
    "    \n",
    "    # add and update dup_time features\n",
    "    test_df, dup_time_matrix, user_accu_dict = update_dup_num(test_df, user_accu_dict, dup_time_matrix, user_master, content_master)\n",
    "    \n",
    "    # merge contents\n",
    "    test_df = pd.concat([test_df.reset_index(drop=True), \n",
    "                        content_base[contents_use_col].reindex(test_df['content_id'].values).reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    # preprocess(elapsed_timeが異常なユーザーをnp.nanにする)\n",
    "    test_df.loc[test_df['prior_question_elapsed_time'] <= 1000, 'prior_question_elapsed_time'] = np.nan\n",
    "            \n",
    "    # category変数対応(null埋め)\n",
    "    test_df['prior_question_had_explanation'].fillna(1, inplace = True)\n",
    "    \n",
    "    # debug用\n",
    "    if check_test:\n",
    "        all_test = all_test.append(test_df)\n",
    "        \n",
    "    # pred(NN)\n",
    "    test_df['answered_correctly'] = (predict_MLP(test_df[use_col_mlp], mlp_params, mlp_model, mlp_ft, inplace=True) * 0.4)\n",
    "        \n",
    "    # pred(LGB)\n",
    "    test_df['answered_correctly'] += (model.predict(test_df[use_col_lgb]) * 0.6)\n",
    "    \n",
    "    set_predict(test_df[['row_id', 'answered_correctly']])\n",
    "    \n",
    "    print('batch end:', round(time.time()-start, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030439,
     "end_time": "2021-01-06T06:52:40.857652",
     "exception": false,
     "start_time": "2021-01-06T06:52:40.827213",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 推論結果デバッグ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T06:52:40.941541Z",
     "iopub.status.busy": "2021-01-06T06:52:40.940695Z",
     "iopub.status.idle": "2021-01-06T06:52:40.944403Z",
     "shell.execute_reply": "2021-01-06T06:52:40.943610Z"
    },
    "papermill": {
     "duration": 0.052923,
     "end_time": "2021-01-06T06:52:40.944530",
     "exception": false,
     "start_time": "2021-01-06T06:52:40.891607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check_testの場合、推論結果をall_testオブジェクトで出力\n",
    "# 内容を確認したいカラムを入力（trainと比較して一致してればOK）\n",
    "if check_test:\n",
    "    check_cols = use_col_mlp\n",
    "\n",
    "    display(all_test[['user_id', 'timestamp'] + check_cols].sort_values(['user_id', 'timestamp']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.048014,
     "end_time": "2021-01-06T06:52:41.038610",
     "exception": false,
     "start_time": "2021-01-06T06:52:40.990596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 77.832132,
   "end_time": "2021-01-06T06:52:42.878846",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-06T06:51:25.046714",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
